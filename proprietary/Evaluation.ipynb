{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580314f0-41b0-4364-8d76-ea73ba267044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q torch_geometric transformers gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e023f3b-1af3-4fff-a3a2-432558ad69c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import gc\n",
    "import torch\n",
    "import gensim\n",
    "import gc\n",
    "import time \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import ndcg_score, average_precision_score\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch_geometric.data import Data, HeteroData, Batch\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.nn import to_hetero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd44d6-fe23-49ca-8936-960431c04874",
   "metadata": {},
   "source": [
    "# Test set performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141f200-d09d-4931-a26b-b98bd93b0379",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc34e1-048b-455d-807f-1d58fdb68170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "li = []\n",
    "\n",
    "# Retrieve ground truth values for each candidate-vacancy pair\n",
    "for truth in os.listdir(\"./graph_data/ground_truth\"):\n",
    "    if \".csv\" in truth:\n",
    "        df = pd.read_csv(f\"./graph_data/ground_truth/{truth}\", header=None)\n",
    "        li.append(df)\n",
    "        \n",
    "# Create truth_dict\n",
    "truths = pd.concat(li, axis=0, ignore_index=True)\n",
    "truth_dict = {key1: dict(group[[1, 2]].values) for key1, group in truths.groupby(0)}\n",
    "\n",
    "# Some candidate-vacancy pairs are not available as a graph, so we filter those out here as well\n",
    "with open(\"./data_subset.json\") as f:\n",
    "    data_subset = json.load(f)\n",
    "    \n",
    "# Filter to relevant graphs\n",
    "truth_dict = {k: {graph: label for graph, label in v.items() if k in data_subset and graph in data_subset[k]} for k, v in truth_dict.items()}\n",
    "truth_dict = {k: v for k, v in truth_dict.items() if not all([i <= 0 for i in v.values()])}\n",
    "\n",
    "data = pd.read_csv(\"./data/cv-vacancy-pairs.csv\")\n",
    "\n",
    "relevant_candidates = set(truth_dict.keys())\n",
    "relevant_vacancies = [set(v.keys()) for _, v in truth_dict.items()]\n",
    "relevant_vacancies = set([item for sublist in relevant_vacancies for item in sublist])\n",
    "\n",
    "cv_data = {}\n",
    "req_data = {}\n",
    "\n",
    "for row in data.itertuples():   \n",
    "        if row[4] not in cv_data and f\"c{row[4]}\" in relevant_candidates:\n",
    "            cv_data[row[4]] = re.sub(r\"\\s+\", \" \", re.sub(\"\\n+\", \"\\n \", re.sub(r\"\\W\", \" \", row[8]))).lower()\n",
    "\n",
    "        if (row[5] not in req_data) and f\"r{row[5]}\" in relevant_vacancies:\n",
    "            req_data[row[5]] = re.sub(r\"\\s+\", \" \", re.sub(\"\\n+\", \"\\n \", re.sub(r\"\\W\", \" \", row[7]))).lower()\n",
    "            \n",
    "training_slice = list(truth_dict.items())[:int(len(truth_dict) * 0.8)]\n",
    "val_slice = list(truth_dict.items())[int(len(truth_dict) * 0.8):int(len(truth_dict) * 0.9)]\n",
    "test_slice = list(truth_dict.items())[int(len(truth_dict) * 0.9):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d7053-103c-4637-9c26-283bd17ef932",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a17b9-63da-4a9b-a487-46cd371fe4f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The first 80% of the data will be used to train the TF-IDF vectorizer\n",
    "training_set = []\n",
    "\n",
    "for candidate, vacancies in training_slice:\n",
    "    training_set.append(cv_data[int(candidate[1:])])\n",
    "    \n",
    "    for vacancy in vacancies:\n",
    "        training_set.append(req_data[int(vacancy[1:])])\n",
    "        \n",
    "# Last 10% is the test set\n",
    "test_set = []\n",
    "\n",
    "for candidate, vacancies in test_slice:\n",
    "    batch = []\n",
    "    \n",
    "    batch.append((candidate, cv_data[int(candidate[1:])]))\n",
    "    \n",
    "    for vacancy, label in vacancies.items():\n",
    "        batch.append((vacancy, req_data[int(vacancy[1:])], label if label >= 0 else 0))\n",
    "        \n",
    "    test_set.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea266c-7039-4866-a210-7a5777ec3fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndcg10_scores = []\n",
    "ndcg5_scores = []\n",
    "ndcg3_scores = []\n",
    "\n",
    "# Embed each CV and its corresponding vacancies using the model, calculate cosine similarity\n",
    "# and evaluate using nDCG\n",
    "for batch in tqdm(test_set):\n",
    "    \n",
    "    ground_truth = []\n",
    "    y_pred = []\n",
    "    \n",
    "    cv_emb = np.random.random(32)\n",
    "    \n",
    "    for _, vacancy, label in batch[1:]:        \n",
    "        req_emb = np.random.random(32)\n",
    "        \n",
    "        ground_truth.append(label)\n",
    "        y_pred.append(cosine_similarity([cv_emb], [req_emb])[0][0])\n",
    "    \n",
    "    ground_truth = np.array(ground_truth)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    ndcg10_scores.append(ndcg_score([ground_truth], [y_pred], k=10))\n",
    "    ndcg5_scores.append(ndcg_score([ground_truth], [y_pred], k=5))\n",
    "    ndcg3_scores.append(ndcg_score([ground_truth], [y_pred], k=3))\n",
    "    \n",
    "print(\"Random test set score:\", f\"nDCG@10: {np.mean(ndcg10_scores)}, nDCG@5: {np.mean(ndcg5_scores)}, nDCG@3: {np.mean(ndcg3_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35954d-18ab-4c6b-9869-605c692c0608",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a5544-5d21-4cd7-9c03-bd4afe220902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "before = time.time()\n",
    "\n",
    "# Initialize model\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_model = vectorizer.fit(training_set)\n",
    "\n",
    "print(time.time() - before)\n",
    "\n",
    "ndcg10_scores = []\n",
    "ndcg5_scores = []\n",
    "ndcg3_scores = []\n",
    "\n",
    "\n",
    "# Embed each CV and its corresponding vacancies using the model, calculate cosine similarity\n",
    "# and evaluate using nDCG\n",
    "for batch in tqdm(test_set):\n",
    "    \n",
    "    ground_truth = []\n",
    "    y_pred = []\n",
    "    \n",
    "    cv_emb = tf_idf_model.transform([batch[0][1]])\n",
    "    \n",
    "    for _, vacancy, label in batch[1:]:        \n",
    "        req_emb = tf_idf_model.transform([vacancy])\n",
    "        \n",
    "        ground_truth.append(label)\n",
    "        y_pred.append(cosine_similarity(cv_emb, req_emb)[0][0])\n",
    "    \n",
    "    ground_truth = np.array(ground_truth)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Calculate nDCG score of current batch        \n",
    "    ndcg10_scores.append(ndcg_score([ground_truth], [y_pred], k=10))\n",
    "    ndcg5_scores.append(ndcg_score([ground_truth], [y_pred], k=5))\n",
    "    ndcg3_scores.append(ndcg_score([ground_truth], [y_pred], k=3))\n",
    "\n",
    "print(\"TF-IDF test set score:\", f\"nDCG@10: {np.mean(ndcg10_scores)}, nDCG@5: {np.mean(ndcg5_scores)}, nDCG@3: {np.mean(ndcg3_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35665bfa-70de-4810-a697-85aa81918545",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94720704-1a97-46cb-a12b-b467f8c968aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_config = {\"min_count\": 5, \"window_size\": 10, \"vector_size\": 32, \"epochs\": 40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593c2764-6856-4196-becb-453daa5491aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "before = time.time()\n",
    "\n",
    "documents = [TaggedDocument(gensim.utils.simple_preprocess(doc), [i]) for i, doc in enumerate(training_set)]\n",
    "\n",
    "d2v_model = Doc2Vec(vector_size=best_config[\"vector_size\"], window=best_config[\"window_size\"], min_count=best_config[\"min_count\"], epochs=best_config[\"epochs\"], workers=4)\n",
    "d2v_model.build_vocab(documents)\n",
    "d2v_model.train(documents, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "\n",
    "print(time.time() - before)\n",
    "\n",
    "ndcg10_scores = []\n",
    "ndcg5_scores = []\n",
    "ndcg3_scores = []\n",
    "\n",
    "for batch in test_set:\n",
    "    ground_truth = []\n",
    "    y_pred = []\n",
    "\n",
    "    cv_emb = d2v_model.infer_vector(gensim.utils.simple_preprocess(batch[0][1]))\n",
    "\n",
    "    for _, vacancy, label in batch[1:]:\n",
    "        vacancy_emb = d2v_model.infer_vector(gensim.utils.simple_preprocess(vacancy))\n",
    "        ground_truth.append(label)\n",
    "        y_pred.append(cosine_similarity([cv_emb], [vacancy_emb])[0][0])\n",
    "\n",
    "    ndcg10_scores.append(ndcg_score([ground_truth], [y_pred], k=10))\n",
    "    ndcg5_scores.append(ndcg_score([ground_truth], [y_pred], k=5))\n",
    "    ndcg3_scores.append(ndcg_score([ground_truth], [y_pred], k=3))\n",
    "\n",
    "print(\"D2V test set score:\", f\"nDCG@10: {np.mean(ndcg10_scores)}, nDCG@5: {np.mean(ndcg5_scores)}, nDCG@3: {np.mean(ndcg3_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09f96d-25aa-46d9-82ce-d4a2ad2b5cdc",
   "metadata": {},
   "source": [
    "## e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a12bded-20f6-47e1-a393-2a1232282518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e5_best_config = {\"epochs\": 1, \"pooling\": \"mean\", \"learning_rate\": 0.0000018572950835516}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f4b570-1c48-4bc4-9183-e1af8a80381d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class e5_ranker(torch.nn.Module):\n",
    "    def __init__(self, pooling=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(\"intfloat/multilingual-e5-small\")\n",
    "        self.pooling = pooling\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "\n",
    "        # Process all embeddings in one go\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        if self.pooling == \"mean\":\n",
    "            # Mean pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size())\n",
    "            sum_embeddings = torch.sum(outputs.last_hidden_state * input_mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)  # Avoid division by zero\n",
    "            embeddings = sum_embeddings / sum_mask\n",
    "        elif self.pooling == \"sum\":\n",
    "            # Sum pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size())\n",
    "            embeddings = torch.sum(outputs.last_hidden_state * input_mask_expanded, 1)\n",
    "        elif self.pooling == \"max\":\n",
    "            # Max pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size()).bool()\n",
    "            masked_embeddings = outputs.last_hidden_state * input_mask_expanded  # Apply mask to zero out padding tokens\n",
    "            embeddings, _ = torch.max(masked_embeddings, dim=1)  # Obtain max across the sequence dimension\n",
    "        \n",
    "        # Extract CV and request embeddings\n",
    "        cv_embedding = embeddings[0].unsqueeze(0)  # CV is the first in the batch\n",
    "        req_embeddings = embeddings[1:]  # rest are requests\n",
    "            \n",
    "        # Use the cosine similarity as the score (based on the paper)\n",
    "        return F.cosine_similarity(cv_embedding, req_embeddings).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1552f0a6-27dd-47d4-aef3-c8f5237abf9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenDataLoader(Dataset):\n",
    "    def __init__(self, truth_dict, cv_data, req_data, query_size=512, batch_size=32):\n",
    "        self.ground_truths = list(truth_dict.items())\n",
    "        self.cv_texts = cv_data\n",
    "        self.req_texts = req_data\n",
    "        \n",
    "        self.query_size = query_size\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-small\")\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        # Adjust the length to account for the number of batches based on candidates\n",
    "        return (len(self.ground_truths) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        candidate, vacancies = self.ground_truths[idx]\n",
    "        req_ids, labels = vacancies.keys(), list(vacancies.values())\n",
    "\n",
    "        candidate_text = \"query: \" + self.cv_texts[int(candidate[1:])]\n",
    "        vacancy_texts = [\"passage: \" + self.req_texts[int(v[1:])] for v in req_ids]\n",
    "        input_texts = [candidate_text] + vacancy_texts\n",
    "        \n",
    "        # Tokenize together to ensure consistent padding\n",
    "        tokens = self.tokenizer(input_texts, add_special_tokens=True, padding=True, truncation=True, max_length=self.query_size, return_tensors='pt').to(device)\n",
    "\n",
    "        # Differentiating between -1 and 0 is practically impossible, so they are considered to be the same\n",
    "        labels = [i if i >=0 else 0 for i in labels]\n",
    "\n",
    "        return (candidate, list(req_ids)), tokens, torch.LongTensor(labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d35a27-aea3-4bf9-bdc7-acb670e92c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device, torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627856c-b010-4caf-9d2b-1c3c1d7364be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def listwise_loss(scores, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the LambdaRank loss. (assume sigma=1.)\n",
    "    \n",
    "    scores: tensor of size [N, 1] (the output of a neural network), where N = length of <query, document> pairs\n",
    "    labels: tensor of size [N], contains the relevance labels \n",
    "    \n",
    "    returns: a tensor of size [N, 1]\n",
    "    \"\"\"\n",
    "    if labels.size(0) < 2:\n",
    "        return torch.Tensor([[0]])\n",
    "\n",
    "    N = torch.arange(len(scores))\n",
    "    num_docs = len(scores)\n",
    "\n",
    "    sigma = 1\n",
    "\n",
    "\n",
    "    # Calculate lambda_{i, j} for every <i, j>.\n",
    "    S_j = torch.stack([labels] * num_docs)\n",
    "    S_i = S_j.T\n",
    "    #TODO: remove torch.nan_to_num? Changing it to fill_diagonal(0) seemed to break it somehow, even though it shouldnt..\n",
    "    S = torch.nan_to_num((S_i - S_j) / (S_i - S_j).abs())\n",
    "    lamda = (sigma * (0.5 * (1 - S) - (1 / (1 + torch.exp(sigma * (scores - scores.T)))))) #.sum(axis=1).unsqueeze(1)\n",
    "\n",
    "    # Calculate abs(Delta-NDCG) for each ordering <i, j> combination\n",
    "    sorted_ind = torch.flip(scores.argsort(dim=0).flatten(), dims=[0])\n",
    "    sorted_labels = labels[sorted_ind]\n",
    "    ideal_labels = torch.sort(labels)[0].flip(dims=[0])\n",
    "    k = (torch.arange(sorted_labels.shape[0]) + 1).to(device)\n",
    "    DCG_ideal_labels = torch.sum((2**ideal_labels - 1) / torch.log(k + 1)) \n",
    "    doc_id_to_rank = torch.Tensor([(sorted_ind == i).nonzero(as_tuple=True)[0] for i in N]).int()\n",
    "    doc_id_to_label = torch.Tensor([sorted_labels[R_i] for R_i in doc_id_to_rank]).int().to(device)\n",
    "        \n",
    "    #TODO: We always do this stack+transpose, make a function of this? (and can't something like meshgrid() do the same?)\n",
    "    #TODO: Put comments to explain things.\n",
    "    R_j = torch.stack([doc_id_to_rank] * num_docs).to(device)\n",
    "    R_i = R_j.T\n",
    "    label_j = torch.stack([doc_id_to_label] * num_docs).to(device)\n",
    "    label_i = label_j.T\n",
    "    DCG_discount = ((2**label_i - 1) / torch.log(R_i + 2) + (2**label_j - 1) / torch.log(R_j + 2)).to(device)\n",
    "    DCG_gain = ((2**label_j - 1) / torch.log(R_i + 2) + (2**label_i - 1) / torch.log(R_j + 2)).to(device)\n",
    "    delta_NDCG = ((DCG_gain - DCG_discount) / DCG_ideal_labels).abs()\n",
    "\n",
    "    lambda_rank_loss =  (lamda * delta_NDCG).sum(axis=1).unsqueeze(1) \n",
    "    \n",
    "    return lambda_rank_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda2ba8-b2a9-41ae-a6e9-f197e86cd4a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, learning_rate, epochs):\n",
    "    \"\"\"\n",
    "    Train a model using the optimal configuration.\n",
    "    \n",
    "    - model: the model to train\n",
    "    - trainloader: the dataloader to use, which should provide tokens/embeddings/texts and labels\n",
    "    - learning_rate: the learning rate to use for the optimizer\n",
    "    - epochs: the number of epochs to train the model for\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    ndcg_scores = []\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        before = time.time()\n",
    "        \n",
    "        for i, batch in enumerate(trainloader):\n",
    "\n",
    "            # Skip empty batches\n",
    "            if not batch:               \n",
    "                break\n",
    "                \n",
    "            # The LLM and graph models have slightly different datastructures\n",
    "            if model.__class__.__name__ in [\"e5_ranker\", \"conSultantBERT\"]:\n",
    "                batch_data, batch_labels = batch\n",
    "            else:\n",
    "                batch_data = batch.to(device)\n",
    "                batch_labels = batch.y\n",
    "\n",
    "            # Make prediction\n",
    "            y_pred = model(batch_data)\n",
    "\n",
    "            # Calculate and propagate loss\n",
    "            optimizer.zero_grad()\n",
    "            ground_truth = batch_labels.squeeze()\n",
    "            lambda_i = listwise_loss(y_pred, ground_truth)\n",
    "            torch.autograd.backward(y_pred, lambda_i.squeeze())\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f\"Epoch: {epoch + 1}/{epochs}, batch: {i + 1}/{len(trainloader)}\", end=\"\\r\")\n",
    "        print(f\"\\n\\nTraining time: {time.time() - before}s\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f01a37-d17b-40fa-ad53-6dcb456889a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, testloader):\n",
    "    \"\"\"\n",
    "    Evaluate a model on unseen data.\n",
    "    \n",
    "    - model: the model to evaluate\n",
    "    - testloader: the dataloader to use, which should provide tokens/embeddings/texts and labels\n",
    "    \"\"\"\n",
    "        \n",
    "    ndcg10_scores = []\n",
    "    ndcg5_scores = []\n",
    "    ndcg3_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(testloader):\n",
    "            \n",
    "            # Skip empty batches\n",
    "            if not batch:\n",
    "                break\n",
    "                                \n",
    "            # The LLM and graph models have slightly different datastructures\n",
    "            if model.__class__.__name__ in [\"e5_ranker\", \"conSultantBERT\"]:\n",
    "                _, batch_data, batch_labels = batch\n",
    "            else:\n",
    "                batch_data = batch.to(device)\n",
    "                batch_labels = batch.y\n",
    "\n",
    "            print(f\"Batch: {i + 1}/{len(testloader)}\", end=\"\\r\")\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model(batch_data)\n",
    "        \n",
    "            # Calculate nDCG score of current batch        \n",
    "            ndcg10_scores.append(ndcg_score(batch_labels.detach().cpu().unsqueeze(0), \n",
    "                                 y_pred.unsqueeze(0).detach().cpu(), k=10))\n",
    "            ndcg5_scores.append(ndcg_score(batch_labels.detach().cpu().unsqueeze(0), \n",
    "                                 y_pred.unsqueeze(0).detach().cpu(), k=5))\n",
    "            ndcg3_scores.append(ndcg_score(batch_labels.detach().cpu().unsqueeze(0), \n",
    "                                 y_pred.unsqueeze(0).detach().cpu(), k=3))\n",
    "            \n",
    "    return f\"nDCG@10: {np.mean(ndcg10_scores)}, nDCG@5: {np.mean(ndcg5_scores)}, nDCG@3: {np.mean(ndcg3_scores)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa2c89-a049-40a8-b07b-8b60ac65396e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_performance(model_type, best_config):\n",
    "\n",
    "    if model_type == \"e5\":\n",
    "        trainloader = torch.load(\"./dataloaders/e5_trainloader.pth\")\n",
    "        testloader = torch.load(\"./dataloaders/e5_testloader.pth\")\n",
    "\n",
    "        model = e5_ranker(pooling=best_config[\"pooling\"]).to(device)\n",
    "    elif model_type == \"consultantbert\":\n",
    "        trainloader = torch.load(\"./dataloaders/bert_trainloader.pth\")\n",
    "        testloader = torch.load(\"./dataloaders/bert_testloader.pth\")\n",
    "\n",
    "        model = conSultantBERT(pooling=best_config[\"pooling\"]).to(device)\n",
    "    elif model_type == \"baselineGNN\":\n",
    "        trainloader = torch.load(\"./dataloaders/graph_trainloader.pth\")\n",
    "        testloader = torch.load(\"./dataloaders/graph_testloader.pth\")\n",
    "        \n",
    "        # Data.metadata() is needed to initialize the heterodata\n",
    "        data = next(iter(trainloader))\n",
    "\n",
    "        # All the different node types\n",
    "        typings = [\"candidate\", \"request\", \"function_name\", \"isco_code\", \n",
    "                   \"education\", \"language\", \"license\", \"skill\", \"company_name\", \n",
    "                   \"function_id\", \"isco_level\", \"workgroup\", \"klass\", \"literal\"]\n",
    "\n",
    "        model = baselineGNNModel(data, \n",
    "                                 typings,\n",
    "                                 text_embedding_size=best_config[\"text_embedding_size\"],\n",
    "                                 embedding_size=best_config[\"embedding_size\"]).to(device)\n",
    "    elif model_type == \"OKRA\":\n",
    "        trainloader = torch.load(\"./dataloaders/graph_trainloader.pth\")\n",
    "        testloader = torch.load(\"./dataloaders/graph_testloader.pth\")\n",
    "        \n",
    "        # Data.metadata() is needed to initialize the heterodata\n",
    "        data = next(iter(trainloader))\n",
    "\n",
    "        # All the different node types\n",
    "        typings = [\"candidate\", \"request\", \"function_name\", \"isco_code\", \n",
    "                   \"education\", \"language\", \"license\", \"skill\", \"company_name\", \n",
    "                   \"function_id\", \"isco_level\", \"workgroup\", \"klass\", \"literal\"]\n",
    "\n",
    "        model = OKRA(data, \n",
    "                     typings,\n",
    "                     text_embedding_size=best_config[\"text_embedding_size\"],\n",
    "                     embedding_size=best_config[\"embedding_size\"]).to(device)\n",
    "    else:\n",
    "        raise Exception(\"Please select one of ['e5', 'consultantbert', 'baselineGNN', 'OKRA']\")\n",
    "        \n",
    "\n",
    "    if not f\"{model.__class__.__name__}.pt\" in os.listdir(\"./trained_models/\"):\n",
    "        model = train_model(model, trainloader, learning_rate=best_config[\"learning_rate\"], epochs=best_config[\"epochs\"])\n",
    "        torch.save(model.state_dict(), f\"./trained_models/{model.__class__.__name__}.pt\")\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(f\"./trained_models/{model.__class__.__name__}.pt\"))\n",
    "    \n",
    "    test_score = evaluate_model(model, testloader)\n",
    "\n",
    "    print(f\"{model.__class__.__name__} test set score:\", test_score)\n",
    "\n",
    "    torch.cuda.empty_cache() \n",
    "    gc.collect()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f96849-7b40-490d-b65f-261bb0254eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e5_ranker = get_model_performance(\"e5\", e5_best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b983fd-96d6-4a2c-a8b0-4b02b587934a",
   "metadata": {},
   "source": [
    "## conSultantBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f7dd53-6722-4742-b0b8-d5b7ce622c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_best_config = {\"pooling\": \"mean\", \"learning_rate\": 0.00000130695542009724, \"epochs\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a5d76-c5dd-480e-bd90-9ff9164e9530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTTokenDataLoader(Dataset):\n",
    "    def __init__(self, truth_dict, cv_data, req_data, query_size=512, batch_size=32):\n",
    "        self.ground_truths = list(truth_dict.items())\n",
    "        self.cv_texts = cv_data\n",
    "        self.req_texts = req_data\n",
    "        \n",
    "        self.query_size = query_size\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        # Adjust the length to account for the number of batches based on candidates\n",
    "        return (len(self.ground_truths) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        candidate, vacancies = self.ground_truths[idx]\n",
    "\n",
    "        req_ids, labels = vacancies.keys(), list(vacancies.values())\n",
    "\n",
    "        candidate_text = self.cv_texts[int(candidate[1:])]\n",
    "        vacancy_texts = [self.req_texts[int(v[1:])] for v in req_ids]\n",
    "        input_texts = [candidate_text] + vacancy_texts\n",
    "        \n",
    "        tokens = self.tokenizer(input_texts, max_length=self.query_size, padding='max_length', truncation=True, return_tensors=\"pt\").to(device)\n",
    "            \n",
    "        # Differentiating between -1 and 0 is practically impossible, so they are considered to be the same\n",
    "        labels = [i if i >=0 else 0 for i in labels]\n",
    "        \n",
    "        return (candidate, list(req_ids)), tokens, torch.LongTensor(labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b3f7f-1ac8-4995-a02a-64e045ad02d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class conSultantBERT(torch.nn.Module):\n",
    "    def __init__(self, pooling):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = BertModel.from_pretrained(\"bert-base-multilingual-cased\").to(device)    \n",
    "        self.pooling = pooling\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "\n",
    "        # Process all embeddings in one go\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        if self.pooling == \"mean\":\n",
    "            # Mean pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size())\n",
    "            sum_embeddings = torch.sum(outputs.last_hidden_state * input_mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)  # Avoid division by zero\n",
    "            embeddings = sum_embeddings / sum_mask\n",
    "        elif self.pooling == \"sum\":\n",
    "            # Sum pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size())\n",
    "            embeddings = torch.sum(outputs.last_hidden_state * input_mask_expanded, 1)\n",
    "        elif self.pooling == \"max\":\n",
    "            # Max pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size()).bool()\n",
    "            masked_embeddings = outputs.last_hidden_state * input_mask_expanded  # Apply mask to zero out padding tokens\n",
    "            embeddings, _ = torch.max(masked_embeddings, dim=1)  # Obtain max across the sequence dimension\n",
    "        \n",
    "        # Extract CV and request embeddings\n",
    "        cv_embedding = embeddings[0].unsqueeze(0)  # CV is the first in the batch\n",
    "        req_embeddings = embeddings[1:]  # rest are requests\n",
    "            \n",
    "        # Use the cosine similarity as the score (based on the paper)\n",
    "        return F.cosine_similarity(cv_embedding, req_embeddings).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214aa132-f269-4111-8fc5-2cd0cfb8a15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cBERT = get_model_performance(\"consultantbert\", bert_best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bbca0-f9af-4893-9412-d9833459cbb8",
   "metadata": {},
   "source": [
    "## BaseGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3b28d-e230-413a-af06-1594d02d1af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gnn_best_config = {\"epochs\": 1, \"embedding_size\": 128, \"text_embedding_size\": 32, \"learning_rate\": 0.0004643543481813991}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525cccd9-e3f9-4459-a179-c0893bb1efd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We embed the textual nodes (candidates and requests) separately at first\n",
    "class base_text_embedding_layer(torch.nn.Module):\n",
    "    def __init__(self, text_embedding_size=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.e5 = AutoModel.from_pretrained(\"intfloat/multilingual-e5-small\").to(device)\n",
    "                \n",
    "        self.candidate_out = nn.Linear(in_features=384,\n",
    "                                       out_features=text_embedding_size)\n",
    "\n",
    "        self.company_out = nn.Linear(in_features=384,\n",
    "                                     out_features=text_embedding_size)\n",
    "        \n",
    "    def average_pool(self, last_hidden_states, attention_mask):\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "        \n",
    "    def forward(self, x_can, x_req, att_mask_can, att_mask_req):\n",
    "        \n",
    "        # Feed tokens into model\n",
    "        x_candidate = self.e5(x_can, att_mask_can)\n",
    "        x_company = self.e5(x_req, att_mask_req)\n",
    "        \n",
    "        # Create embedding tensor\n",
    "        candidate_embeddings = self.average_pool(x_candidate.last_hidden_state, attention_mask=att_mask_can)\n",
    "        company_embeddings = self.average_pool(x_company.last_hidden_state, attention_mask=att_mask_req)\n",
    "\n",
    "        # normalize embeddings\n",
    "        candidate_embeddings = F.normalize(candidate_embeddings, p=2, dim=1)\n",
    "        company_embeddings = F.normalize(company_embeddings, p=2, dim=1)\n",
    "        \n",
    "        # Run through MLP to match other embedding sizes\n",
    "        x_candidate = self.candidate_out(candidate_embeddings).float()\n",
    "        x_company = self.company_out(company_embeddings).float()\n",
    "        \n",
    "        return x_candidate, x_company    \n",
    "    \n",
    "# Then, we embed all nodes initially\n",
    "class base_embedding_layer(torch.nn.Module):\n",
    "    def __init__(self, embedding_size=32):\n",
    "        super().__init__()        \n",
    "        \n",
    "        self.conv = geom_nn.TransformerConv((-1, -1), embedding_size)\n",
    "        self.conv2 = geom_nn.TransformerConv((-1, -1), embedding_size)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "        x = self.conv(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "        \n",
    "class baselineGNNModel(torch.nn.Module):\n",
    "    def __init__(self, data, typings, text_embedding_size=16, embedding_size=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.typings = typings\n",
    "        \n",
    "        self.text_embedder = base_text_embedding_layer(text_embedding_size=text_embedding_size)\n",
    "\n",
    "        self.embedder = base_embedding_layer(embedding_size=embedding_size)\n",
    "        self.embedder = to_hetero(self.embedder, data.metadata(), aggr='sum')        \n",
    "        \n",
    "        self.fc = nn.Linear(embedding_size, 1)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # Embed textual features       \n",
    "        x_candidate, x_request = self.text_embedder(data.x_dict[\"candidate\"], data.x_dict[\"request\"], data[\"candidate\"].att_mask, data[\"request\"].att_mask)\n",
    "        \n",
    "        # Store the textual embeddings along with the rest of the graph\n",
    "        data.x_dict[\"candidate\"] = x_candidate\n",
    "        data.x_dict[\"request\"] = x_request\n",
    "\n",
    "        # Embed the graph as a whole\n",
    "        embedded_data = self.embedder({k: v.float() for k, v in data.x_dict.items()}, data.edge_index_dict)\n",
    "        \n",
    "        # Each sub-graph gets its own embedding\n",
    "        sub_graphs = defaultdict(list)\n",
    "            \n",
    "        # Find the sub-graph of each node in the embedding, and add it to the corresponding list\n",
    "        for typing in self.typings:\n",
    "            for i, emb in enumerate(embedded_data[typing]):            \n",
    "                # Some subgraphs do not have all data types (e.g., a graph might not include any education nodes)\n",
    "                if data[typing]:\n",
    "                    # Find the sub-graph the current node belongs to\n",
    "                    current_node_id = int(data[typing].unique_node_id[i].item())\n",
    "                                        \n",
    "                    # We were working with a dummy node\n",
    "                    if current_node_id == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    sg = int(data[typing].sub_graph[i].item())\n",
    "                                        \n",
    "                    # Add its candidate embedding to its sub-graph embedding\n",
    "                    sub_graphs[sg].append(emb.unsqueeze(0))              \n",
    "\n",
    "        # Finally, mean pool every graph embedding (so the final embedding is the mean of all of the nodes)\n",
    "        for sg in sub_graphs.keys():            \n",
    "            sub_graphs[sg] = torch.mean(torch.stack(sub_graphs[sg]).squeeze(1), dim=0)\n",
    "                                    \n",
    "        # Stack all the sub-graph embeddings into a single matrix, both candidate- and company-sided\n",
    "        sub_graphs = torch.stack([i[1] for i in sorted(sub_graphs.items())], dim=0)\n",
    "                \n",
    "        # Make predictions based on the sub-graph embeddings\n",
    "        y_pred = self.fc(sub_graphs)\n",
    "        \n",
    "        return y_pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a8ec9c-adab-4624-b9a4-4489ff4f3667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gTransformer = get_model_performance(\"baselineGNN\", gnn_best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1fd33-d239-44e4-b1a9-53a89f1f311c",
   "metadata": {},
   "source": [
    "## Okra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d17904-0d2e-4fbf-9763-55be4a5fa170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "okra_best_config = {\"epochs\": 3, \"embedding_size\": 32, \"text_embedding_size\": 128, \n",
    "                    \"text_pooling\": \"token\", \"pooling_method\": \"mean\", \n",
    "                    \"learning_rate\": 0.00005282859517546829}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766880b-cf0b-4d50-b94a-fc13aa1616e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Module, Parameter\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense import Linear\n",
    "from torch_geometric.nn.fx import Transformer\n",
    "from torch_geometric.typing import EdgeType, Metadata, NodeType, SparseTensor\n",
    "from torch_geometric.utils.hetero import get_unused_node_types\n",
    "\n",
    "try:\n",
    "    from torch.fx import Graph, GraphModule, Node\n",
    "except (ImportError, ModuleNotFoundError, AttributeError):\n",
    "    GraphModule, Graph, Node = 'GraphModule', 'Graph', 'Node'\n",
    "\n",
    "\n",
    "def to_hetero_with_bases(module: Module, metadata: Metadata, num_bases: int,\n",
    "                         in_channels: Optional[Dict[str, int]] = None,\n",
    "                         input_map: Optional[Dict[str, str]] = None,\n",
    "                         debug: bool = False) -> GraphModule:\n",
    "\n",
    "    transformer = ToHeteroWithBasesTransformer(module, metadata, num_bases,\n",
    "                                               in_channels, input_map, debug)\n",
    "    return transformer.transform()\n",
    "\n",
    "\n",
    "\n",
    "class ToHeteroWithBasesTransformer(Transformer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: Module,\n",
    "        metadata: Metadata,\n",
    "        num_bases: int,\n",
    "        in_channels: Optional[Dict[str, int]] = None,\n",
    "        input_map: Optional[Dict[str, str]] = None,\n",
    "        debug: bool = False,\n",
    "    ):\n",
    "        super().__init__(module, input_map, debug)\n",
    "\n",
    "        self.metadata = metadata\n",
    "        self.num_bases = num_bases\n",
    "        self.in_channels = in_channels or {}\n",
    "        assert len(metadata) == 2\n",
    "        assert len(metadata[0]) > 0 and len(metadata[1]) > 0\n",
    "\n",
    "        self.validate()\n",
    "\n",
    "        # Compute IDs for each node and edge type:\n",
    "        self.node_type2id = {k: i for i, k in enumerate(metadata[0])}\n",
    "        self.edge_type2id = {k: i for i, k in enumerate(metadata[1])}\n",
    "\n",
    "    def validate(self):\n",
    "        unused_node_types = get_unused_node_types(*self.metadata)\n",
    "        if len(unused_node_types) > 0:\n",
    "            warnings.warn(\n",
    "                f\"There exist node types ({unused_node_types}) whose \"\n",
    "                f\"representations do not get updated during message passing \"\n",
    "                f\"as they do not occur as destination type in any edge type. \"\n",
    "                f\"This may lead to unexpected behavior.\")\n",
    "\n",
    "        names = self.metadata[0] + [rel for _, rel, _ in self.metadata[1]]\n",
    "        for name in names:\n",
    "            if not name.isidentifier():\n",
    "                warnings.warn(\n",
    "                    f\"The type '{name}' contains invalid characters which \"\n",
    "                    f\"may lead to unexpected behavior. To avoid any issues, \"\n",
    "                    f\"ensure that your types only contain letters, numbers \"\n",
    "                    f\"and underscores.\")\n",
    "\n",
    "    def transform(self) -> GraphModule:\n",
    "        self._node_offset_dict_initialized = False\n",
    "        self._edge_offset_dict_initialized = False\n",
    "        self._edge_type_initialized = False\n",
    "        out = super().transform()\n",
    "        del self._node_offset_dict_initialized\n",
    "        del self._edge_offset_dict_initialized\n",
    "        del self._edge_type_initialized\n",
    "        return out\n",
    "\n",
    "    def placeholder(self, node: Node, target: Any, name: str):\n",
    "        if node.type is not None:\n",
    "            Type = EdgeType if self.is_edge_level(node) else NodeType\n",
    "            node.type = Dict[Type, node.type]\n",
    "\n",
    "        out = node\n",
    "\n",
    "        # Create `node_offset_dict` and `edge_offset_dict` dictionaries in case\n",
    "        # they are not yet initialized. These dictionaries hold the cumulated\n",
    "        # sizes used to create a unified graph representation and to split the\n",
    "        # output data.\n",
    "        if self.is_edge_level(node) and not self._edge_offset_dict_initialized:\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node('call_function',\n",
    "                                         target=get_edge_offset_dict,\n",
    "                                         args=(node, self.edge_type2id),\n",
    "                                         name='edge_offset_dict')\n",
    "            self._edge_offset_dict_initialized = True\n",
    "\n",
    "        elif not self._node_offset_dict_initialized:\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node('call_function',\n",
    "                                         target=get_node_offset_dict,\n",
    "                                         args=(node, self.node_type2id),\n",
    "                                         name='node_offset_dict')\n",
    "            self._node_offset_dict_initialized = True\n",
    "\n",
    "        # Create a `edge_type` tensor used as input to `HeteroBasisConv`:\n",
    "        if self.is_edge_level(node) and not self._edge_type_initialized:\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node('call_function', target=get_edge_type,\n",
    "                                         args=(node, self.edge_type2id),\n",
    "                                         name='edge_type')\n",
    "            self._edge_type_initialized = True\n",
    "\n",
    "        # Add `Linear` operation to align features to the same dimensionality:\n",
    "        if name in self.in_channels:\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node('call_module',\n",
    "                                         target=f'align_lin__{name}',\n",
    "                                         args=(node, ),\n",
    "                                         name=f'{name}__aligned')\n",
    "            self._state[out.name] = self._state[name]\n",
    "\n",
    "            lin = LinearAlign(self.metadata[int(self.is_edge_level(node))],\n",
    "                              self.in_channels[name])\n",
    "            setattr(self.module, f'align_lin__{name}', lin)\n",
    "\n",
    "        # Perform grouping of type-wise values into a single tensor:\n",
    "        if self.is_edge_level(node):\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node(\n",
    "                'call_function', target=group_edge_placeholder,\n",
    "                args=(out if name in self.in_channels else node,\n",
    "                      self.edge_type2id,\n",
    "                      self.find_by_name('node_offset_dict')),\n",
    "                name=f'{name}__grouped')\n",
    "            self._state[out.name] = 'edge'\n",
    "\n",
    "        else:\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node(\n",
    "                'call_function', target=group_node_placeholder,\n",
    "                args=(out if name in self.in_channels else node,\n",
    "                      self.node_type2id), name=f'{name}__grouped')\n",
    "            self._state[out.name] = 'node'\n",
    "\n",
    "        self.replace_all_uses_with(node, out)\n",
    "\n",
    "    def call_message_passing_module(self, node: Node, target: Any, name: str):\n",
    "        # Call the `HeteroBasisConv` wrapper instead instead of a single\n",
    "        # message passing layer. We need to inject the `edge_type` as first\n",
    "        # argument in order to do so.\n",
    "        node.args = (self.find_by_name('edge_type'), ) + node.args\n",
    "\n",
    "    def output(self, node: Node, target: Any, name: str):\n",
    "        # Split the output to dictionaries, holding either node type-wise or\n",
    "        # edge type-wise data.\n",
    "        def _recurse(value: Any) -> Any:\n",
    "            if isinstance(value, Node) and self.is_edge_level(value):\n",
    "                self.graph.inserting_before(node)\n",
    "                return self.graph.create_node(\n",
    "                    'call_function', target=split_output,\n",
    "                    args=(value, self.find_by_name('edge_offset_dict')),\n",
    "                    name=f'{value.name}__split')\n",
    "\n",
    "                pass\n",
    "            elif isinstance(value, Node):\n",
    "                self.graph.inserting_before(node)\n",
    "                return self.graph.create_node(\n",
    "                    'call_function', target=split_output,\n",
    "                    args=(value, self.find_by_name('node_offset_dict')),\n",
    "                    name=f'{value.name}__split')\n",
    "\n",
    "            elif isinstance(value, dict):\n",
    "                return {k: _recurse(v) for k, v in value.items()}\n",
    "            elif isinstance(value, list):\n",
    "                return [_recurse(v) for v in value]\n",
    "            elif isinstance(value, tuple):\n",
    "                return tuple(_recurse(v) for v in value)\n",
    "            else:\n",
    "                return value\n",
    "\n",
    "        if node.type is not None and isinstance(node.args[0], Node):\n",
    "            output = node.args[0]\n",
    "            Type = EdgeType if self.is_edge_level(output) else NodeType\n",
    "            node.type = Dict[Type, node.type]\n",
    "        else:\n",
    "            node.type = None\n",
    "\n",
    "        node.args = (_recurse(node.args[0]), )\n",
    "\n",
    "    def init_submodule(self, module: Module, target: str) -> Module:\n",
    "        if not isinstance(module, MessagePassing):\n",
    "            return module\n",
    "\n",
    "        # Replace each `MessagePassing` module by a `HeteroBasisConv` wrapper:\n",
    "        return HeteroBasisConv(module, len(self.metadata[1]), self.num_bases)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "class HeteroBasisConv(torch.nn.Module):\n",
    "    # A wrapper layer that applies the basis-decomposition technique to a\n",
    "    # heterogeneous graph.\n",
    "    def __init__(self, module: MessagePassing, num_relations: int,\n",
    "                 num_bases: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "\n",
    "        # We make use of a post-message computation hook to inject the\n",
    "        # basis re-weighting for each individual edge type.\n",
    "        # This currently requires us to set `conv.fuse = False`, which leads\n",
    "        # to a materialization of messages.\n",
    "        def hook(module, inputs, output):\n",
    "            assert isinstance(module._edge_type, Tensor)\n",
    "            if module._edge_type.size(0) != output.size(0):\n",
    "                raise ValueError(\n",
    "                    f\"Number of messages ({output.size(0)}) does not match \"\n",
    "                    f\"with the number of original edges \"\n",
    "                    f\"({module._edge_type.size(0)}). Does your message \"\n",
    "                    f\"passing layer create additional self-loops? Try to \"\n",
    "                    f\"remove them via 'add_self_loops=False'\")\n",
    "            weight = module.edge_type_weight.view(-1)[module._edge_type]\n",
    "            weight = weight.view([-1] + [1] * (output.dim() - 1))\n",
    "            return weight * output\n",
    "\n",
    "        params = list(module.parameters())\n",
    "        device = params[0].device if len(params) > 0 else 'cpu'\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_bases):\n",
    "            conv = copy.deepcopy(module)\n",
    "            conv.fuse = False  # Disable `message_and_aggregate` functionality.\n",
    "            # We learn a single scalar weight for each individual edge type,\n",
    "            # which is used to weight the output message based on edge type:\n",
    "            conv.edge_type_weight = Parameter(\n",
    "                torch.empty(1, num_relations, device=device))\n",
    "            conv.register_message_forward_hook(hook)\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        if self.num_bases > 1:\n",
    "            self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            if hasattr(conv, 'reset_parameters'):\n",
    "                conv.reset_parameters()\n",
    "            elif sum([p.numel() for p in conv.parameters()]) > 0:\n",
    "                warnings.warn(\n",
    "                    f\"'{conv}' will be duplicated, but its parameters cannot \"\n",
    "                    f\"be reset. To suppress this warning, add a \"\n",
    "                    f\"'reset_parameters()' method to '{conv}'\")\n",
    "            torch.nn.init.xavier_uniform_(conv.edge_type_weight)\n",
    "\n",
    "    def forward(self, edge_type: Tensor, *args, **kwargs) -> Tensor:\n",
    "        out = None\n",
    "        \n",
    "        attention = []\n",
    "        \n",
    "        # Call message passing modules and perform aggregation:\n",
    "        for conv in self.convs:\n",
    "            conv._edge_type = edge_type\n",
    "                        \n",
    "            res, (edge_ind_exp, att_weight_exp) = conv(*args, **kwargs)\n",
    "            del conv._edge_type\n",
    "            \n",
    "            attention.append(att_weight_exp)\n",
    "            \n",
    "            out = res if out is None else out.add_(res)\n",
    "            \n",
    "            # jump\n",
    "            \n",
    "        return out, (edge_type, edge_ind_exp, torch.mean(torch.stack(attention, dim=0), dim=0))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(num_relations='\n",
    "                f'{self.num_relations}, num_bases={self.num_bases})')\n",
    "\n",
    "\n",
    "class LinearAlign(torch.nn.Module):\n",
    "    # Aligns representions to the same dimensionality. Note that this will\n",
    "    # create lazy modules, and as such requires a forward pass in order to\n",
    "    # initialize parameters.\n",
    "    def __init__(self, keys: List[Union[NodeType, EdgeType]],\n",
    "                 out_channels: int):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.lins = torch.nn.ModuleDict()\n",
    "        for key in keys:\n",
    "            self.lins[key2str(key)] = Linear(-1, out_channels, bias=False)\n",
    "\n",
    "    def forward(\n",
    "        self, x_dict: Dict[Union[NodeType, EdgeType], Tensor]\n",
    "    ) -> Dict[Union[NodeType, EdgeType], Tensor]:\n",
    "        return {key: self.lins[key2str(key)](x) for key, x in x_dict.items()}\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(num_relations={len(self.lins)}, '\n",
    "                f'out_channels={self.out_channels})')\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# These methods are used in order to receive the cumulated sizes of input\n",
    "# dictionaries. We make use of them for creating a unified homogeneous graph\n",
    "# representation, as well as to split the final output data once again.\n",
    "\n",
    "\n",
    "def get_node_offset_dict(\n",
    "    input_dict: Dict[NodeType, Union[Tensor, SparseTensor]],\n",
    "    type2id: Dict[NodeType, int],\n",
    ") -> Dict[NodeType, int]:\n",
    "    cumsum = 0\n",
    "    out: Dict[NodeType, int] = {}\n",
    "    for key in type2id.keys():\n",
    "        out[key] = cumsum\n",
    "        cumsum += input_dict[key].size(0)\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_edge_offset_dict(\n",
    "    input_dict: Dict[EdgeType, Union[Tensor, SparseTensor]],\n",
    "    type2id: Dict[EdgeType, int],\n",
    ") -> Dict[EdgeType, int]:\n",
    "    cumsum = 0\n",
    "    out: Dict[EdgeType, int] = {}\n",
    "    for key in type2id.keys():\n",
    "        out[key] = cumsum\n",
    "        value = input_dict[key]\n",
    "        if isinstance(value, SparseTensor):\n",
    "            cumsum += value.nnz()\n",
    "        elif value.dtype == torch.long and value.size(0) == 2:\n",
    "            cumsum += value.size(-1)\n",
    "        else:\n",
    "            cumsum += value.size(0)\n",
    "    return out\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# This method computes the edge type of the final homogeneous graph\n",
    "# representation. It will be used in the `HeteroBasisConv` wrapper.\n",
    "\n",
    "\n",
    "def get_edge_type(\n",
    "    input_dict: Dict[EdgeType, Union[Tensor, SparseTensor]],\n",
    "    type2id: Dict[EdgeType, int],\n",
    ") -> Tensor:\n",
    "\n",
    "    inputs = [input_dict[key] for key in type2id.keys()]\n",
    "    outs = []\n",
    "\n",
    "    for i, value in enumerate(inputs):\n",
    "        if value.size(0) == 2 and value.dtype == torch.long:  # edge_index\n",
    "            out = value.new_full((value.size(-1), ), i, dtype=torch.long)\n",
    "        elif isinstance(value, SparseTensor):\n",
    "            out = torch.full((value.nnz(), ), i, dtype=torch.long,\n",
    "                             device=value.device())\n",
    "        else:\n",
    "            out = value.new_full((value.size(0), ), i, dtype=torch.long)\n",
    "        outs.append(out)\n",
    "\n",
    "    return outs[0] if len(outs) == 1 else torch.cat(outs, dim=0)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# These methods are used to group the individual type-wise components into a\n",
    "# unfied single representation.\n",
    "\n",
    "\n",
    "def group_node_placeholder(input_dict: Dict[NodeType, Tensor],\n",
    "                           type2id: Dict[NodeType, int]) -> Tensor:\n",
    "\n",
    "    inputs = [input_dict[key] for key in type2id.keys()]\n",
    "    return inputs[0] if len(inputs) == 1 else torch.cat(inputs, dim=0)\n",
    "\n",
    "\n",
    "def group_edge_placeholder(\n",
    "    input_dict: Dict[EdgeType, Union[Tensor, SparseTensor]],\n",
    "    type2id: Dict[EdgeType, int],\n",
    "    offset_dict: Dict[NodeType, int] = None,\n",
    ") -> Union[Tensor, SparseTensor]:\n",
    "\n",
    "    inputs = [input_dict[key] for key in type2id.keys()]\n",
    "\n",
    "    if len(inputs) == 1:\n",
    "        return inputs[0]\n",
    "\n",
    "    # In case of grouping a graph connectivity tensor `edge_index` or `adj_t`,\n",
    "    # we need to increment its indices:\n",
    "    elif inputs[0].size(0) == 2 and inputs[0].dtype == torch.long:\n",
    "        if offset_dict is None:\n",
    "            raise AttributeError(\n",
    "                \"Can not infer node-level offsets. Please ensure that there \"\n",
    "                \"exists a node-level argument before the 'edge_index' \"\n",
    "                \"argument in your forward header.\")\n",
    "\n",
    "        outputs = []\n",
    "        for value, (src_type, _, dst_type) in zip(inputs, type2id):\n",
    "            value = value.clone()\n",
    "            value[0, :] += offset_dict[src_type]\n",
    "            value[1, :] += offset_dict[dst_type]\n",
    "            outputs.append(value)\n",
    "\n",
    "        return torch.cat(outputs, dim=-1)\n",
    "\n",
    "    elif isinstance(inputs[0], SparseTensor):\n",
    "        if offset_dict is None:\n",
    "            raise AttributeError(\n",
    "                \"Can not infer node-level offsets. Please ensure that there \"\n",
    "                \"exists a node-level argument before the 'SparseTensor' \"\n",
    "                \"argument in your forward header.\")\n",
    "\n",
    "        # For grouping a list of SparseTensors, we convert them into a\n",
    "        # unified `edge_index` representation in order to avoid conflicts\n",
    "        # induced by re-shuffling the data.\n",
    "        rows, cols = [], []\n",
    "        for value, (src_type, _, dst_type) in zip(inputs, type2id):\n",
    "            col, row, value = value.coo()\n",
    "            assert value is None\n",
    "            rows.append(row + offset_dict[src_type])\n",
    "            cols.append(col + offset_dict[dst_type])\n",
    "\n",
    "        row = torch.cat(rows, dim=0)\n",
    "        col = torch.cat(cols, dim=0)\n",
    "        return torch.stack([row, col], dim=0)\n",
    "\n",
    "    else:\n",
    "        return torch.cat(inputs, dim=0)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# This method is used to split the output tensors into individual type-wise\n",
    "# components:\n",
    "\n",
    "\n",
    "def split_output(\n",
    "    output: Tensor,\n",
    "    offset_dict: Union[Dict[NodeType, int], Dict[EdgeType, int]],\n",
    ") -> Union[Dict[NodeType, Tensor], Dict[EdgeType, Tensor]]:\n",
    "    \n",
    "    # Sometimes an edge index ends up here. Not sure why. TODO: fix --> we should be able to determine which edge belongs\n",
    "    # to which edge type\n",
    "    if type(output) == tuple:\n",
    "        return output\n",
    "    elif output.size(0) == 2:\n",
    "        output = output.T\n",
    "        \n",
    "    cumsums = list(offset_dict.values()) + [output.size(0)]    \n",
    "    sizes = [cumsums[i + 1] - cumsums[i] for i in range(len(offset_dict))]\n",
    "    outputs = output.split(sizes)\n",
    "    return {key: output for key, output in zip(offset_dict, outputs)}\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def key2str(key: Union[NodeType, EdgeType]) -> str:\n",
    "    key = '__'.join(key) if isinstance(key, tuple) else key\n",
    "    return key.replace(' ', '_').replace('-', '_').replace(':', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23fbc3-f21d-4967-a3d6-73360ea56336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We embed the textual nodes (candidates and requests) separately at first\n",
    "class text_embedding_layer(torch.nn.Module):\n",
    "    def __init__(self, text_embedding_size=64, text_pooling=\"token\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.e5 = AutoModel.from_pretrained(\"intfloat/multilingual-e5-small\").to(device)\n",
    "        \n",
    "        self.text_pooling = text_pooling\n",
    "                \n",
    "        self.candidate_out = nn.Linear(in_features=384,\n",
    "                                       out_features=text_embedding_size)\n",
    "\n",
    "        self.company_out = nn.Linear(in_features=384,\n",
    "                                     out_features=text_embedding_size)\n",
    "        \n",
    "    def average_pool(self, last_hidden_states, attention_mask):\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "        \n",
    "    def forward(self, x_can, x_req, att_mask_can, att_mask_req):\n",
    "        \n",
    "        # Feed tokens into model\n",
    "        x_candidate = self.e5(x_can, att_mask_can)\n",
    "        x_company = self.e5(x_req, att_mask_req)\n",
    "        \n",
    "        if self.text_pooling == \"token\":\n",
    "            # Create embedding tensor\n",
    "            candidate_embeddings = self.average_pool(x_candidate.last_hidden_state, attention_mask=att_mask_can)\n",
    "            company_embeddings = self.average_pool(x_company.last_hidden_state, attention_mask=att_mask_req)\n",
    "\n",
    "            # normalize embeddings\n",
    "            candidate_embeddings = F.normalize(candidate_embeddings, p=2, dim=1)\n",
    "            company_embeddings = F.normalize(company_embeddings, p=2, dim=1)\n",
    "        elif self.text_pooling == \"sentence\":\n",
    "            # Mean pooling\n",
    "            input_mask_expanded = att_mask_can.unsqueeze(-1).expand(x_candidate.last_hidden_state.size())\n",
    "            sum_embeddings = torch.sum(x_candidate.last_hidden_state * input_mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)  # Avoid division by zero\n",
    "            candidate_embeddings = sum_embeddings / sum_mask\n",
    "            \n",
    "            input_mask_expanded = att_mask_req.unsqueeze(-1).expand(x_company.last_hidden_state.size())\n",
    "            sum_embeddings = torch.sum(x_company.last_hidden_state * input_mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)  # Avoid division by zero\n",
    "            company_embeddings = sum_embeddings / sum_mask\n",
    "\n",
    "        # Run through MLP to match other embedding sizes\n",
    "        x_candidate = self.candidate_out(candidate_embeddings).float()\n",
    "        x_company = self.company_out(company_embeddings).float()\n",
    "        \n",
    "        return x_candidate, x_company  \n",
    "    \n",
    "# Then, we embed all nodes initially\n",
    "class embedding_layer(torch.nn.Module):\n",
    "    def __init__(self, embedding_size=32):\n",
    "        super().__init__()        \n",
    "        \n",
    "        self.conv1 = geom_nn.TransformerConv((-1, -1), embedding_size)\n",
    "        self.conv2 = geom_nn.TransformerConv((-1, -1), embedding_size)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "       \n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "        \n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, embedding_size=64, heads=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.can_pos = geom_nn.GATv2Conv((-1, -1),\n",
    "                                         out_channels=embedding_size,\n",
    "                                         add_self_loops=False,\n",
    "                                         heads=heads,\n",
    "                                         concat=False)\n",
    "        \n",
    "        self.can_neg = geom_nn.GATv2Conv((-1, -1),\n",
    "                                         out_channels=embedding_size,\n",
    "                                         add_self_loops=False,\n",
    "                                         heads=heads,\n",
    "                                         concat=False)\n",
    "        self.com_pos = geom_nn.GATv2Conv((-1, -1),\n",
    "                                         out_channels=embedding_size,\n",
    "                                         add_self_loops=False,\n",
    "                                         heads=heads,\n",
    "                                         concat=False)\n",
    "\n",
    "        self.com_neg = geom_nn.GATv2Conv((-1, -1),\n",
    "                                         out_channels=embedding_size,\n",
    "                                         add_self_loops=False,\n",
    "                                         heads=heads,\n",
    "                                         concat=False)\n",
    "        \n",
    "        # Different batch norm for each GATv2 output, as it includes learned parameters\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(embedding_size)\n",
    "        self.batch_norm2 = torch.nn.BatchNorm1d(embedding_size)\n",
    "        self.batch_norm3 = torch.nn.BatchNorm1d(embedding_size)\n",
    "        self.batch_norm4 = torch.nn.BatchNorm1d(embedding_size)\n",
    "\n",
    "        self.dense_can = nn.Linear(in_features=embedding_size,\n",
    "                                   out_features=heads)\n",
    "    \n",
    "        self.dense_com = nn.Linear(in_features=embedding_size,\n",
    "                                   out_features=heads)\n",
    "    \n",
    "        \n",
    "        self.elu = nn.ELU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, edge_index):            \n",
    "        ### Positive candidate-side attention\n",
    "        x_can_pos, can_pos_exp = self.can_pos(x, \n",
    "                                              edge_index.long(), \n",
    "                                              return_attention_weights=True)\n",
    "        \n",
    "        ### Negative candidate-side attention        \n",
    "        x_can_neg, can_neg_exp = self.can_neg(x_can_pos, \n",
    "                                              edge_index.long(), \n",
    "                                              return_attention_weights=True)\n",
    "\n",
    "        ### Positive company-side attention\n",
    "        # We flip the edge index to distinguish this as a 'company-side' graph\n",
    "        x_com_pos, com_pos_exp = self.com_pos(x * -1, \n",
    "                                              edge_index[[1, 0]].long(), \n",
    "                                              return_attention_weights=True)\n",
    "\n",
    "        ### Negative company-side attention\n",
    "        x_com_neg, com_neg_exp = self.com_neg(x_com_pos, \n",
    "                                              edge_index[[1, 0]].long(), \n",
    "                                              return_attention_weights=True)\n",
    "        \n",
    "        # Edge embedding\n",
    "        e_im_can = self.sigmoid(\n",
    "                            torch.sum(\n",
    "                                torch.stack([can_pos_exp[2], \n",
    "                                             can_neg_exp[2]], \n",
    "                                      dim=0), \n",
    "                                dim=0)\n",
    "                    )        \n",
    "        \n",
    "        e_im_com = self.sigmoid(\n",
    "                            torch.sum(\n",
    "                                torch.stack([com_pos_exp[2], \n",
    "                                             com_neg_exp[2]], \n",
    "                                        dim=0), \n",
    "                                dim=0)\n",
    "                    )\n",
    "        \n",
    "        x_can_pos = self.batch_norm1(x_can_pos)\n",
    "        x_can_neg = self.batch_norm2(x_can_neg)\n",
    "        \n",
    "        x_com_pos = self.batch_norm3(x_com_pos)\n",
    "        x_com_neg = self.batch_norm4(x_com_neg)\n",
    "         \n",
    "        # Mean pool\n",
    "        x_can = torch.mean(torch.stack([self.elu(x_can_pos), \n",
    "                                        self.elu(x_can_neg)]), dim=0)\n",
    "        \n",
    "        x_com = torch.mean(torch.stack([self.elu(x_com_pos), \n",
    "                                        self.elu(x_com_neg)]), dim=0)\n",
    "            \n",
    "        # Node embedding\n",
    "        v_im_can = self.dense_can(x_can).relu()\n",
    "        v_im_com = self.dense_com(x_com).relu()\n",
    "        \n",
    "        return x_can, x_com, v_im_can, v_im_com, e_im_can, e_im_com,\\\n",
    "               can_pos_exp, can_neg_exp, com_pos_exp, com_neg_exp\n",
    "    \n",
    "class OKRA(torch.nn.Module):\n",
    "    def __init__(self, data, typings, embedding_size=64, text_embedding_size=64, pooling_method=\"mean\", text_pooling=\"token\", heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.typings = typings\n",
    "        self.num_heads = heads\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.pooling = {\n",
    "            \"mean\": lambda x, dim: torch.mean(x, dim=dim),\n",
    "            \"sum\": lambda x, dim: torch.sum(x, dim=dim),\n",
    "            # Only return the values for max pooling, ignoring the indices\n",
    "            \"max\": lambda x, dim: torch.max(x, dim=dim)[0]\n",
    "        }[pooling_method]\n",
    "        \n",
    "        self.text_embedder = text_embedding_layer(text_embedding_size=text_embedding_size, text_pooling=text_pooling)\n",
    "\n",
    "        self.embedder = embedding_layer(embedding_size=embedding_size)\n",
    "        self.embedder = to_hetero(self.embedder, data.metadata(), aggr='sum')\n",
    "\n",
    "        self.gnn = GNN(embedding_size=embedding_size, heads=heads)\n",
    "        self.gnn = to_hetero_with_bases(self.gnn, data.metadata(), num_bases=3)\n",
    "        \n",
    "        # Each embedding is the size heads * embedding_size * 3, as there is one heads * embedding_size embedding for each (head node, tail node, sub-graph)\n",
    "        self.mlp_candidate = nn.Linear(in_features=heads * embedding_size * 3,\n",
    "                                       out_features=1)\n",
    "        \n",
    "        self.mlp_company = nn.Linear(in_features=heads * embedding_size * 3,\n",
    "                                     out_features=1)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # Embed textual features       \n",
    "        x_candidate, x_request = self.text_embedder(data.x_dict[\"candidate\"], data.x_dict[\"request\"], data[\"candidate\"].att_mask, data[\"request\"].att_mask)\n",
    "        \n",
    "        # Store the textual embeddings along with the rest of the graph\n",
    "        data.x_dict[\"candidate\"] = x_candidate\n",
    "        data.x_dict[\"request\"] = x_request\n",
    "\n",
    "        # Embed the graph as a whole\n",
    "        embedded_data = self.embedder({k: v.float() for k, v in data.x_dict.items()}, data.edge_index_dict)\n",
    "       \n",
    "        # Run the embedded graph through the GNN\n",
    "        x_can, x_com, v_im_can1, v_im_com1, e_im_can, e_im_com, \\\n",
    "        can_pos_exp, can_neg_exp, com_pos_exp, com_neg_exp = self.gnn(embedded_data, \n",
    "                                                                      data.edge_index_dict)\n",
    "        \n",
    "        # Combine the attention with the values, once per head, for both the candidate and company side\n",
    "        h_can = defaultdict(lambda : torch.Tensor([]).to(device))\n",
    "        h_com = defaultdict(lambda : torch.Tensor([]).to(device))\n",
    "    \n",
    "        # Store each node as a combination of its head embeddings\n",
    "        for typing in self.typings:\n",
    "            for k in range(self.num_heads):\n",
    "                if typing in x_can:\n",
    "                    h_can[typing] = torch.cat([h_can[typing], (x_can[typing].T * v_im_can1[typing][:,k]).T], dim=1)\n",
    "                else:\n",
    "                    h_can[typing] = torch.cat([h_can[typing], torch.zeros_like(h_can[list(h_can.keys())[0]].T)])\n",
    "                \n",
    "                if typing in x_com:\n",
    "                    h_com[typing] = torch.cat([h_com[typing], (x_com[typing].T * v_im_com1[typing][:,k]).T], dim=1)\n",
    "                else:\n",
    "                    h_com[typing] = torch.cat([h_com[typing], torch.zeros_like(h_com[list(h_com.keys())[0]].T)])\n",
    "                            \n",
    "        # Each sub-graph gets its own embedding\n",
    "        sub_graphs_candidate = defaultdict(list)\n",
    "        sub_graphs_company = defaultdict(list)\n",
    "        \n",
    "        # Additionally, the head and tail node (candidate and vacancy) get stored separately as well\n",
    "        main_nodes_candidate = defaultdict(list)\n",
    "        main_nodes_company = defaultdict(list)\n",
    "        \n",
    "\n",
    "                                               \n",
    "        # Find the sub-graph of each node in the embedding, and add it to the corresponding list\n",
    "        for typing in self.typings:\n",
    "            for i, emb in enumerate(h_can[typing]):            \n",
    "                # Some subgraphs do not have all data types (e.g., a graph might not include any education nodes)\n",
    "                if data[typing]:\n",
    "                    # Find the sub-graph the current node belongs to\n",
    "                    current_node_id = int(data[typing].unique_node_id[i].item())\n",
    "                                        \n",
    "                    # We were working with a dummy node\n",
    "                    if current_node_id == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    sg = int(data[typing].sub_graph[i].item())\n",
    "                    \n",
    "                    # If our node is a head/tail node, store it accordingly\n",
    "                    if (in_head := (current_node_id in data.head_nodes[0])) or (in_tail := (current_node_id in data.tail_nodes[0])):                        \n",
    "                        main_nodes_candidate[sg].append(emb)\n",
    "                        main_nodes_company[sg].append(h_com[typing][i])\n",
    "                    \n",
    "                    # Add its candidate embedding to its sub-graph embedding\n",
    "                    sub_graphs_candidate[sg].append(emb.unsqueeze(0))\n",
    "\n",
    "                    # Do the same on the company side\n",
    "                    sub_graphs_company[sg].append(h_com[typing][i].unsqueeze(0))               \n",
    "\n",
    "        # Finally, pool every graph embedding (so the final embedding is the mean of all of the nodes)\n",
    "        for sg in sub_graphs_candidate.keys():            \n",
    "            sub_graphs_candidate[sg] = self.pooling(torch.stack(sub_graphs_candidate[sg]).squeeze(1), dim=0)\n",
    "            sub_graphs_company[sg] = self.pooling(torch.stack(sub_graphs_company[sg]).squeeze(1), dim=0)\n",
    "                                        \n",
    "            # Add the head and tail node to the full embedding\n",
    "            sub_graphs_candidate[sg] = torch.cat([torch.cat(main_nodes_candidate[sg], dim=0).squeeze(), sub_graphs_candidate[sg]])\n",
    "            sub_graphs_company[sg] = torch.cat([torch.cat(main_nodes_company[sg], dim=0).squeeze(), sub_graphs_company[sg]])\n",
    "                        \n",
    "        # Stack all the sub-graph embeddings into a single matrix, both candidate- and company-sided\n",
    "        sub_graphs_candidate = torch.stack([i[1] for i in sorted(sub_graphs_candidate.items())], dim=0)\n",
    "        sub_graphs_company = torch.stack([i[1] for i in sorted(sub_graphs_company.items())], dim=0)\n",
    "                \n",
    "        # Make predictions based on the sub-graph embeddings\n",
    "        y_candidate = torch.clamp(self.mlp_candidate(sub_graphs_candidate), min=-100, max=100)\n",
    "        y_company = torch.clamp(self.mlp_company(sub_graphs_company), min=-100, max=100)\n",
    "        \n",
    "        # Final prediction is the harmonic mean of the candidate- and company-sided prediction\n",
    "        y_pred = 2 * ((y_candidate * y_company) / (y_candidate + y_company))\n",
    "        \n",
    "        # The harmonic mean of X and 0 should be 0, not nan\n",
    "        y_pred = torch.nan_to_num(y_pred).squeeze()\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48679d-56bd-4da1-9ac8-4c8b9e447879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "okra = get_model_performance(\"OKRA\", okra_best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee4eff2-d75a-4fec-a508-416841202ee8",
   "metadata": {},
   "source": [
    "# Fairness evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce68374-4c08-4691-b57b-a3297194b6ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/cv-vacancy-pairs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1aef3-f3e3-4de8-9657-42fcb037a5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests = pd.read_csv(\"./data/requests.csv\")\n",
    "request_locations = pd.read_csv(\"./data/request_locations.csv\")[[\"client_mgmcompany_companynumber\", \"client_mgmcompany_cacheddetails_address_postalcode\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e205a3e1-f2c3-457b-93e1-e83479e4ad2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_locations[\"client_mgmcompany_companynumber\"] = request_locations[\"client_mgmcompany_companynumber\"].astype('Int64').fillna(-1)\n",
    "request_locations[\"client_mgmcompany_cacheddetails_address_postalcode\"] = request_locations[\"client_mgmcompany_cacheddetails_address_postalcode\"].apply(lambda x: x[:4] if not pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16c081-a82a-426b-9a79-19fdea53552e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_locations = request_locations[request_locations['client_mgmcompany_cacheddetails_address_postalcode'].str.match(r'^\\d{4}$', na=False)]\n",
    "request_locations[\"client_mgmcompany_cacheddetails_address_postalcode\"] = request_locations[\"client_mgmcompany_cacheddetails_address_postalcode\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b33810-8be2-4b90-b34e-20c47c83f6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests[\"request_company_name\"] = requests[\"request_company_name\"].str.lower().str.strip()\n",
    "requests[\"request_company_name\"] = requests[\"request_company_name\"].str.replace('[^a-zA-Z0-9]', '_', regex=True).str.strip()\n",
    "\n",
    "requests[\"request_company_name\"].value_counts().sort_values().plot(loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63552df1-7a09-4051-bd3a-4332944f133a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb946a-47ba-4377-a406-2b5c1e6e7359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(requests[[\"request_mondriaan_number\", \"request_company_number\"]], \n",
    "                     request_locations, \n",
    "                     how=\"left\", \n",
    "                     left_on=\"request_company_number\", \n",
    "                     right_on=\"client_mgmcompany_companynumber\")[[\"request_mondriaan_number\", \"client_mgmcompany_cacheddetails_address_postalcode\"]]\n",
    "                                                                 \n",
    "merged_df = merged_df.drop_duplicates(subset=\"request_mondriaan_number\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5fd6bb-60d9-4e18-8034-da96ec7ed483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load candidate locations\n",
    "candidate_locs = pd.read_csv(\"./data/location.csv\") #[[\"candidate_id\", \"from_post_code\"]]\n",
    "\n",
    "candidate_locs.at[1108034, \"date_start\"] = \"2018-02-01 00:00:00\"\n",
    "candidate_locs.at[1476463, \"date_start\"] = \"2016-09-01 00:00:00\"\n",
    "candidate_locs.at[1596093, \"date_start\"] = \"2020-10-26 00:00:00\"\n",
    "\n",
    "\n",
    "# Convert 'start_date' to datetime\n",
    "candidate_locs['date_start'] = pd.to_datetime(candidate_locs['date_start'])\n",
    "\n",
    "# Filter the DataFrame to keep only rows with the most recent 'start_date' for each 'user_id'\n",
    "candidate_locs = candidate_locs[candidate_locs['date_start'] == candidate_locs.groupby('candidate_id')['date_start'].transform('max')]\n",
    "\n",
    "# Postal code to municipality conversion\n",
    "zip_to_mun = pd.read_csv(\"./data/georef-netherlands-postcode-pc4.csv\", encoding=\"utf-8\", on_bad_lines=\"skip\", delimiter=\";\")[[\"PC4\", \"Provincie name\", \"Gemeente name\"]]\n",
    "\n",
    "randstad_municipalities = {\"Amsterdam\", \"Rotterdam\", \"Utrecht\", \"Den Haag\", \"Haarlemmermeer\", \"Zaandam\", \"Heemskerk\", \"Beverwijk\", \"Velsen\", \"Oostzaan\", \"Landsmeer\", \"Haarlem\", \"Bloemendaal\", \n",
    "                           \"Zandvoort\", \"Diemen\", \"Gooise Meren\", \"Almere\", \"Huizen\", \"Blaricum\", \"Laren\", \"Hilversum\", \"Baarn\", \"Wijdemeren\", \"Amstelveen\", \"Ouderamstel\", \"Aalsmeer\", \"Uithoorn\", \n",
    "                           \"Heemstede\", \"Eemnes\", \"Bunschoten\", \"Amersfoort\", \"Soest\", \"Zesit\", \"De Bilt\", \"Stichtse Vechte\", \"De Ronde Venen\", \"Woerden\", \"Bunnik\", \"Houten\", \"Nieuwegein\", \"IJsselstein\",\n",
    "                           \"Woerden\", \"Oudewater\", \"Montfoort\", \"Lopik\", \"Vijfherenlanden\", \"Nieuwkoop\", \"Kaag en Braassem\", \"Teylingen\", \"Lisse\", \"Hillegom\", \"Noordwijk\", \"Katwijk\", \"Oegstgeest\",\n",
    "                           \"Leiden\", \"Leiderdorp\", \"Alphen aan de Rijn\", \"Wassenaar\", \"Voorschoten\", \"Zoeterwoude\", \"Bodegraven-Reeuwijk\", \"Waddinxveen\", \"Gouda\", \"Krimpenerwaard\", \"Molenlanden\",\n",
    "                           \"Gorinchem\", \"Hardinxveld-Giessendam\", \"Sliedrecht\", \"Dordrecht\", \"Papendrecht\", \"Hoeksche Waard\", \"Nissewaard\", \"Voorne aan Zee\", \"Alblasserdam\", \"Ridderkerk\", \"Hendrik-Ido-Ambacht\",\n",
    "                           \"Zwijndrecht\", \"Barendrecht\", \"Albrandswaard\", \"Krimpen\", \"Capelle\", \"Capelle aan den IJssel\", \"Zuidplas\", \"Lansingerland\", \"Zoetermeer\", \"Zoeterwoude\", \"Leidschendam-Voorburg\",\n",
    "                           \"'s-Gravenhage\", \"Rijswijk\", \"Pijnacker-nootdrop\", \"Delft\", \"Midden-delfland\", \"Westland\", \"Maassluis\", \"Vlaardingen\", \"Schiedam\"}\n",
    "\n",
    "randstad_municipalities = {i.lower() for i in randstad_municipalities}\n",
    "\n",
    "# Find which zip codes fall in Randstad-municipalities\n",
    "randstad_zips = zip_to_mun[zip_to_mun[\"Gemeente name\"].str.lower().isin(randstad_municipalities)][[\"PC4\", \"Gemeente name\"]]\n",
    "\n",
    "# Add True/False column\n",
    "randstad_zips = set(randstad_zips[\"PC4\"].unique())\n",
    "candidate_locs[\"in_randstad\"] = candidate_locs[\"from_post_code\"].apply(lambda x: int(x[:4])).isin(randstad_zips)\n",
    "\n",
    "merged_df[\"in_randstad\"] = merged_df[\"client_mgmcompany_cacheddetails_address_postalcode\"].apply(lambda x: int(x) if not pd.isna(x) else -1).isin(randstad_zips)\n",
    "\n",
    "# Convert to dictionary for easy look-up\n",
    "ran_dict = candidate_locs[[\"candidate_id\", \"in_randstad\"]].to_dict()\n",
    "ran_dict_candidates = {\"c\" + str(ran_dict[\"candidate_id\"][k]): ran_dict[\"in_randstad\"][k] for k in ran_dict[\"candidate_id\"].keys()}\n",
    "\n",
    "# Convert to dictionary for easy look-up\n",
    "ran_dict = merged_df[[\"request_mondriaan_number\", \"in_randstad\"]].to_dict()\n",
    "ran_dict_requests = {\"r\" + str(ran_dict[\"request_mondriaan_number\"][k]): ran_dict[\"in_randstad\"][k] for k in ran_dict[\"request_mondriaan_number\"].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0141890-bf67-44be-baae-465a52b0ba03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rc of Randstad-based companies\n",
    "np.mean(merged_df[\"in_randstad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aec083-2bea-4804-96a3-825253e695cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(candidate_locs[\"in_randstad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc123a07-cb8a-42fe-92cf-513bb3887764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_location_fairness(model, test_set, ran_dict_candidates, ran_dict_requests, R_c):    \n",
    "    if model == \"random\":\n",
    "        print(model)\n",
    "    else:\n",
    "        print(model.__class__.__name__)\n",
    "    \n",
    "    torch_model = True\n",
    "    \n",
    "    if model.__class__.__name__ == \"e5_ranker\":\n",
    "        dataloader = torch.load(\"./dataloaders/e5_testloader.pth\")\n",
    "    elif model.__class__.__name__ == \"conSultantBERT\":\n",
    "        dataloader = torch.load(\"./dataloaders/bert_testloader.pth\")\n",
    "    elif model.__class__.__name__ in [\"baselineGNNModel\", \"OKRA\"]:\n",
    "        dataloader = torch.load(\"./dataloaders/graph_testloader.pth\")\n",
    "    elif model.__class__.__name__ in [\"TfidfVectorizer\", \"Doc2Vec\"] or model == \"random\":\n",
    "        dataloader = test_set\n",
    "        torch_model = False\n",
    "    else:\n",
    "        raise Exception(\"Invalid model provided\")\n",
    "    \n",
    "    ndcg_urban = []\n",
    "    ndcg_rural = []\n",
    "    \n",
    "    rec_share_rural = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):                \n",
    "            if torch_model:\n",
    "                # The LLM and graph models have slightly different datastructures\n",
    "                if model.__class__.__name__ in [\"e5_ranker\", \"conSultantBERT\"]:\n",
    "                    (candidate, requests), batch_data, batch_labels = batch\n",
    "                else:\n",
    "                    batch_data = batch.to(device)\n",
    "                    batch_labels = batch.y\n",
    "                    candidate = batch_data.tups[0][0][0]\n",
    "                    requests = [i[1] for i in batch_data.tups[0]]\n",
    "\n",
    "                print(f\"Batch: {i + 1}/{len(testloader)}\", end=\"\\r\")\n",
    "\n",
    "                # Make predictions\n",
    "                y_pred = model(batch_data)\n",
    "\n",
    "\n",
    "                # Calculate nDCG score of current batch        \n",
    "                score = ndcg_score(batch_labels.detach().cpu().unsqueeze(0), \n",
    "                                   y_pred.unsqueeze(0).detach().cpu(), k=10)\n",
    "                \n",
    "            else:\n",
    "                ground_truth = []\n",
    "                y_pred = []\n",
    "                requests = []\n",
    "                \n",
    "                candidate = batch[0][0]\n",
    "                \n",
    "                if model.__class__.__name__ == \"TfidfVectorizer\":\n",
    "                    cv_emb = model.transform([batch[0][1]])\n",
    "                    \n",
    "                    for request, vacancy, label in batch[1:]:        \n",
    "                        req_emb = model.transform([vacancy])\n",
    "                        ground_truth.append(label)\n",
    "                        y_pred.append(cosine_similarity(cv_emb, req_emb)[0][0])\n",
    "                        requests.append(request)\n",
    "                    \n",
    "                elif model.__class__.__name__ == \"Doc2Vec\":\n",
    "                    cv_emb = model.infer_vector(gensim.utils.simple_preprocess(batch[0][1]))\n",
    "                    \n",
    "                    for request, vacancy, label in batch[1:]:\n",
    "                        req_emb = model.infer_vector(gensim.utils.simple_preprocess(vacancy))\n",
    "                        ground_truth.append(label)\n",
    "                        y_pred.append(cosine_similarity([cv_emb], [req_emb])[0][0])\n",
    "                        requests.append(request)\n",
    "                            \n",
    "                elif model == \"random\":\n",
    "                    cv_emb = np.random.random(32)\n",
    "                    \n",
    "                    for request, vacancy, label in batch[1:]:\n",
    "                        req_emb = np.random.random(32)\n",
    "                        ground_truth.append(label)\n",
    "                        y_pred.append(cosine_similarity([cv_emb], [req_emb])[0][0])\n",
    "                        requests.append(request)                \n",
    "\n",
    "                ground_truth = np.array(ground_truth)\n",
    "                y_pred = np.array(y_pred)\n",
    "\n",
    "                score = ndcg_score([ground_truth], [y_pred], k=10)\n",
    "            \n",
    "            # We assume candidates for whom we do not have data live outside of the Randstad\n",
    "            if ran_dict_candidates.get(candidate, False):\n",
    "                ndcg_urban.append(score)\n",
    "            else:\n",
    "                ndcg_rural.append(score)\n",
    "                \n",
    "            # Calculate share of recommendations for items of the in-group\n",
    "            if torch_model:\n",
    "                request_dist = zip(requests, [ran_dict_requests.get(req, False) for req in requests], y_pred.detach().cpu().numpy())\n",
    "            else:\n",
    "                request_dist = zip(requests, [ran_dict_requests.get(req, False) for req in requests], y_pred)\n",
    "                \n",
    "            top_10_requests = list(sorted(request_dist, key = lambda x: -x[2]))[:10]\n",
    "            \n",
    "            # Rural means NOT in_randstad\n",
    "            rui_i_in_Ic = np.sum([not(i[1]) for i in top_10_requests])\n",
    "            R_hat = 10\n",
    "            \n",
    "            # Number of items in the protected group / number of recommendations\n",
    "            rec_share_rural.append(rui_i_in_Ic / R_hat)\n",
    "                          \n",
    "    return {\"Urban ndcg\" : (np.mean(ndcg_urban), np.std(ndcg_urban), len(ndcg_urban)), \n",
    "            \"Rural ndcg\": (np.mean(ndcg_rural), np.std(ndcg_rural), len(ndcg_rural)),\n",
    "            \"Performance disparity\": np.mean(ndcg_rural) - np.mean(ndcg_urban),\n",
    "            \"Disparate visibility\" : (np.mean(rec_share_rural) - R_c, np.std(rec_share_rural), len(rec_share_rural))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee75369-0c62-4d3d-80b1-07658e38139a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testloader = torch.load(\"./dataloaders/graph_testloader.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef791f0-1e0b-4ec5-9c6b-9540b61a3078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model_type in [\"random\", \"tf-idf\", \"d2v\", \"e5_ranker\", \"conSultantBERT\", \"baselineGNNModel\", \"OKRA\"]:\n",
    "    if model_type == \"random\":\n",
    "        model = \"random\"\n",
    "    elif model_type == \"tf-idf\":\n",
    "        model = tf_idf_model\n",
    "    elif model_type == \"d2v\":\n",
    "        model = d2v_model\n",
    "    elif model_type == \"e5_ranker\":\n",
    "        model = e5_ranker(pooling=e5_best_config[\"pooling\"]).to(device)\n",
    "    elif model_type == \"conSultantBERT\":\n",
    "        model = conSultantBERT(pooling=bert_best_config[\"pooling\"]).to(device)\n",
    "    elif model_type == \"baselineGNNModel\":      \n",
    "        # Data.metadata() is needed to initialize the heterodata\n",
    "        data = next(iter(testloader))\n",
    "\n",
    "        # All the different node types\n",
    "        typings = [\"candidate\", \"request\", \"function_name\", \"isco_code\", \n",
    "                   \"education\", \"language\", \"license\", \"skill\", \"company_name\", \n",
    "                   \"function_id\", \"isco_level\", \"workgroup\", \"klass\", \"literal\"]\n",
    "\n",
    "        model = baselineGNNModel(data, \n",
    "                                 typings,\n",
    "                                 text_embedding_size=gnn_best_config[\"text_embedding_size\"],\n",
    "                                 embedding_size=gnn_best_config[\"embedding_size\"]).to(device)\n",
    "    elif model_type == \"OKRA\":\n",
    "        # Data.metadata() is needed to initialize the heterodata\n",
    "        data = next(iter(testloader))\n",
    "\n",
    "        # All the different node types\n",
    "        typings = [\"candidate\", \"request\", \"function_name\", \"isco_code\", \n",
    "                   \"education\", \"language\", \"license\", \"skill\", \"company_name\", \n",
    "                   \"function_id\", \"isco_level\", \"workgroup\", \"klass\", \"literal\"]\n",
    "\n",
    "        model = OKRA(data,\n",
    "                     typings,\n",
    "                     text_embedding_size=okra_best_config[\"text_embedding_size\"],\n",
    "                     text_pooling=okra_best_config[\"text_pooling\"],\n",
    "                     embedding_size=okra_best_config[\"embedding_size\"],\n",
    "                     pooling_method=okra_best_config[\"pooling_method\"],\n",
    "                     heads=4).to(device)  \n",
    "\n",
    "    if model_type in [\"e5_ranker\", \"conSultantBERT\", \"baselineGNNModel\", \"OKRA\"]:\n",
    "        model.load_state_dict(torch.load(f\"./trained_models/{model.__class__.__name__}.pt\"))\n",
    "    \n",
    "    \n",
    "    fairness_scores = eval_location_fairness(model, test_set, ran_dict_candidates, ran_dict_requests, R_c=1 - np.mean(merged_df[\"in_randstad\"]))\n",
    "    print(fairness_scores)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70366ff-dac3-4af2-a5f0-943b1005e10b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
