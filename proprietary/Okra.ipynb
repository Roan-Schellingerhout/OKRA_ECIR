{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c869e-5c7b-4aea-ac00-066e263e2b59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q torch-geometric==2.5.2 gensim transformers wandb optuna optuna_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cacec-4ce4-4583-8bc9-e78d68ae55ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import json\n",
    "import torch_geometric\n",
    "import re\n",
    "import gc\n",
    "import wandb\n",
    "import optuna\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "from torch_geometric.data import Data, HeteroData, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.nn import to_hetero\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import ndcg_score\n",
    "from itertools import groupby, permutations\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e5b4ba-0fbd-4079-a713-974c68eb27a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch_geometric.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643686c-0c91-4103-a2c9-b6e1f1f2b112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252f8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device, torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b9c9f4-a387-4652-9d79-74649a9d9671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloader = torch.load(\"./dataloaders/graph_trainloader.pth\")\n",
    "valloader = torch.load(\"./dataloaders/graph_valloader.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085adff-f82b-4cf0-8606-4b272ee0a96d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Module, Parameter\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense import Linear\n",
    "from torch_geometric.nn.fx import Transformer\n",
    "from torch_geometric.typing import EdgeType, Metadata, NodeType, SparseTensor\n",
    "from torch_geometric.utils.hetero import get_unused_node_types\n",
    "\n",
    "try:\n",
    "    from torch.fx import Graph, GraphModule, Node\n",
    "except (ImportError, ModuleNotFoundError, AttributeError):\n",
    "    GraphModule, Graph, Node = 'GraphModule', 'Graph', 'Node'\n",
    "\n",
    "\n",
    "def to_hetero_with_bases(module: Module, metadata: Metadata, num_bases: int,\n",
    "                         in_channels: Optional[Dict[str, int]] = None,\n",
    "                         input_map: Optional[Dict[str, str]] = None,\n",
    "                         debug: bool = False) -> GraphModule:\n",
    "\n",
    "    transformer = ToHeteroWithBasesTransformer(module, metadata, num_bases,\n",
    "                                               in_channels, input_map, debug)\n",
    "    return transformer.transform()\n",
    "\n",
    "\n",
    "\n",
    "class ToHeteroWithBasesTransformer(Transformer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: Module,\n",
    "        metadata: Metadata,\n",
    "        num_bases: int,\n",
    "        in_channels: Optional[Dict[str, int]] = None,\n",
    "        input_map: Optional[Dict[str, str]] = None,\n",
    "        debug: bool = False,\n",
    "    ):\n",
    "        super().__init__(module, input_map, debug)\n",
    "\n",
    "        self.metadata = metadata\n",
    "        self.num_bases = num_bases\n",
    "        self.in_channels = in_channels or {}\n",
    "        assert len(metadata) == 2\n",
    "        assert len(metadata[0]) > 0 and len(metadata[1]) > 0\n",
    "\n",
    "        self.validate()\n",
    "\n",
    "        # Compute IDs for each node and edge type:\n",
    "        self.node_type2id = {k: i for i, k in enumerate(metadata[0])}\n",
    "        self.edge_type2id = {k: i for i, k in enumerate(metadata[1])}\n",
    "\n",
    "    def validate(self):\n",
    "        unused_node_types = get_unused_node_types(*self.metadata)\n",
    "        if len(unused_node_types) > 0:\n",
    "            warnings.warn(\n",
    "                f\"There exist node types ({unused_node_types}) whose \"\n",
    "                f\"representations do not get updated during message passing \"\n",
    "                f\"as they do not occur as destination type in any edge type. \"\n",
    "                f\"This may lead to unexpected behavior.\")\n",
    "\n",
    "        names = self.metadata[0] + [rel for _, rel, _ in self.metadata[1]]\n",
    "        for name in names:\n",
    "            if not name.isidentifier():\n",
    "                warnings.warn(\n",
    "                    f\"The type '{name}' contains invalid characters which \"\n",
    "                    f\"may lead to unexpected behavior. To avoid any issues, \"\n",
    "                    f\"ensure that your types only contain letters, numbers \"\n",
    "                    f\"and underscores.\")\n",
    "\n",
    "    def transform(self) -> GraphModule:\n",
    "        self._node_offset_dict_initialized = False\n",
    "        self._edge_offset_dict_initialized = False\n",
    "        self._edge_type_initialized = False\n",
    "        out = super().transform()\n",
    "        del self._node_offset_dict_initialized\n",
    "        del self._edge_offset_dict_initialized\n",
    "        del self._edge_type_initialized\n",
    "        return out\n",
    "\n",
    "    def placeholder(self, node: Node, target: Any, name: str):\n",
    "        if node.type is not None:\n",
    "            Type = EdgeType if self.is_edge_level(node) else NodeType\n",
    "            node.type = Dict[Type, node.type]\n",
    "\n",
    "        out = node\n",
    "\n",
    "        # Create `node_offset_dict` and `edge_offset_dict` dictionaries in case\n",
    "        # they are not yet initialized. These dictionaries hold the cumulated\n",
    "        # sizes used to create a unified graph representation and to split the\n",
    "        # output data.\n",
    "        if self.is_edge_level(node) and not self._edge_offset_dict_initialized:\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node('call_function',\n",
    "                                         target=get_edge_offset_dict,\n",
    "                                         args=(node, self.edge_type2id),\n",
    "                                         name='edge_offset_dict')\n",
    "            self._edge_offset_dict_initialized = True\n",
    "\n",
    "        elif not self._node_offset_dict_initialized:\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node('call_function',\n",
    "                                         target=get_node_offset_dict,\n",
    "                                         args=(node, self.node_type2id),\n",
    "                                         name='node_offset_dict')\n",
    "            self._node_offset_dict_initialized = True\n",
    "\n",
    "        # Create a `edge_type` tensor used as input to `HeteroBasisConv`:\n",
    "        if self.is_edge_level(node) and not self._edge_type_initialized:\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node('call_function', target=get_edge_type,\n",
    "                                         args=(node, self.edge_type2id),\n",
    "                                         name='edge_type')\n",
    "            self._edge_type_initialized = True\n",
    "\n",
    "        # Add `Linear` operation to align features to the same dimensionality:\n",
    "        if name in self.in_channels:\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node('call_module',\n",
    "                                         target=f'align_lin__{name}',\n",
    "                                         args=(node, ),\n",
    "                                         name=f'{name}__aligned')\n",
    "            self._state[out.name] = self._state[name]\n",
    "\n",
    "            lin = LinearAlign(self.metadata[int(self.is_edge_level(node))],\n",
    "                              self.in_channels[name])\n",
    "            setattr(self.module, f'align_lin__{name}', lin)\n",
    "\n",
    "        # Perform grouping of type-wise values into a single tensor:\n",
    "        if self.is_edge_level(node):\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node(\n",
    "                'call_function', target=group_edge_placeholder,\n",
    "                args=(out if name in self.in_channels else node,\n",
    "                      self.edge_type2id,\n",
    "                      self.find_by_name('node_offset_dict')),\n",
    "                name=f'{name}__grouped')\n",
    "            self._state[out.name] = 'edge'\n",
    "\n",
    "        else:\n",
    "            self.graph.inserting_after(out)\n",
    "            out = self.graph.create_node(\n",
    "                'call_function', target=group_node_placeholder,\n",
    "                args=(out if name in self.in_channels else node,\n",
    "                      self.node_type2id), name=f'{name}__grouped')\n",
    "            self._state[out.name] = 'node'\n",
    "\n",
    "        self.replace_all_uses_with(node, out)\n",
    "\n",
    "    def call_message_passing_module(self, node: Node, target: Any, name: str):\n",
    "        # Call the `HeteroBasisConv` wrapper instead instead of a single\n",
    "        # message passing layer. We need to inject the `edge_type` as first\n",
    "        # argument in order to do so.\n",
    "        node.args = (self.find_by_name('edge_type'), ) + node.args\n",
    "\n",
    "    def output(self, node: Node, target: Any, name: str):\n",
    "        # Split the output to dictionaries, holding either node type-wise or\n",
    "        # edge type-wise data.\n",
    "        def _recurse(value: Any) -> Any:\n",
    "            if isinstance(value, Node) and self.is_edge_level(value):\n",
    "                self.graph.inserting_before(node)\n",
    "                return self.graph.create_node(\n",
    "                    'call_function', target=split_output,\n",
    "                    args=(value, self.find_by_name('edge_offset_dict')),\n",
    "                    name=f'{value.name}__split')\n",
    "\n",
    "                pass\n",
    "            elif isinstance(value, Node):\n",
    "                self.graph.inserting_before(node)\n",
    "                return self.graph.create_node(\n",
    "                    'call_function', target=split_output,\n",
    "                    args=(value, self.find_by_name('node_offset_dict')),\n",
    "                    name=f'{value.name}__split')\n",
    "\n",
    "            elif isinstance(value, dict):\n",
    "                return {k: _recurse(v) for k, v in value.items()}\n",
    "            elif isinstance(value, list):\n",
    "                return [_recurse(v) for v in value]\n",
    "            elif isinstance(value, tuple):\n",
    "                return tuple(_recurse(v) for v in value)\n",
    "            else:\n",
    "                return value\n",
    "\n",
    "        if node.type is not None and isinstance(node.args[0], Node):\n",
    "            output = node.args[0]\n",
    "            Type = EdgeType if self.is_edge_level(output) else NodeType\n",
    "            node.type = Dict[Type, node.type]\n",
    "        else:\n",
    "            node.type = None\n",
    "\n",
    "        node.args = (_recurse(node.args[0]), )\n",
    "\n",
    "    def init_submodule(self, module: Module, target: str) -> Module:\n",
    "        if not isinstance(module, MessagePassing):\n",
    "            return module\n",
    "\n",
    "        # Replace each `MessagePassing` module by a `HeteroBasisConv` wrapper:\n",
    "        return HeteroBasisConv(module, len(self.metadata[1]), self.num_bases)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "class HeteroBasisConv(torch.nn.Module):\n",
    "    # A wrapper layer that applies the basis-decomposition technique to a\n",
    "    # heterogeneous graph.\n",
    "    def __init__(self, module: MessagePassing, num_relations: int,\n",
    "                 num_bases: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "\n",
    "        # We make use of a post-message computation hook to inject the\n",
    "        # basis re-weighting for each individual edge type.\n",
    "        # This currently requires us to set `conv.fuse = False`, which leads\n",
    "        # to a materialization of messages.\n",
    "        def hook(module, inputs, output):\n",
    "            assert isinstance(module._edge_type, Tensor)\n",
    "            if module._edge_type.size(0) != output.size(0):\n",
    "                raise ValueError(\n",
    "                    f\"Number of messages ({output.size(0)}) does not match \"\n",
    "                    f\"with the number of original edges \"\n",
    "                    f\"({module._edge_type.size(0)}). Does your message \"\n",
    "                    f\"passing layer create additional self-loops? Try to \"\n",
    "                    f\"remove them via 'add_self_loops=False'\")\n",
    "            weight = module.edge_type_weight.view(-1)[module._edge_type]\n",
    "            weight = weight.view([-1] + [1] * (output.dim() - 1))\n",
    "            return weight * output\n",
    "\n",
    "        params = list(module.parameters())\n",
    "        device = params[0].device if len(params) > 0 else 'cpu'\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_bases):\n",
    "            conv = copy.deepcopy(module)\n",
    "            conv.fuse = False  # Disable `message_and_aggregate` functionality.\n",
    "            # We learn a single scalar weight for each individual edge type,\n",
    "            # which is used to weight the output message based on edge type:\n",
    "            conv.edge_type_weight = Parameter(\n",
    "                torch.empty(1, num_relations, device=device))\n",
    "            conv.register_message_forward_hook(hook)\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        if self.num_bases > 1:\n",
    "            self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            if hasattr(conv, 'reset_parameters'):\n",
    "                conv.reset_parameters()\n",
    "            elif sum([p.numel() for p in conv.parameters()]) > 0:\n",
    "                warnings.warn(\n",
    "                    f\"'{conv}' will be duplicated, but its parameters cannot \"\n",
    "                    f\"be reset. To suppress this warning, add a \"\n",
    "                    f\"'reset_parameters()' method to '{conv}'\")\n",
    "            torch.nn.init.xavier_uniform_(conv.edge_type_weight)\n",
    "\n",
    "    def forward(self, edge_type: Tensor, *args, **kwargs) -> Tensor:\n",
    "        out = None\n",
    "        \n",
    "        attention = []\n",
    "        \n",
    "        # Call message passing modules and perform aggregation:\n",
    "        for conv in self.convs:\n",
    "            conv._edge_type = edge_type\n",
    "                        \n",
    "            res, (edge_ind_exp, att_weight_exp) = conv(*args, **kwargs)\n",
    "            del conv._edge_type\n",
    "            \n",
    "            attention.append(att_weight_exp)\n",
    "            \n",
    "            out = res if out is None else out.add_(res)\n",
    "            \n",
    "            # jump\n",
    "        \n",
    "        return out, (edge_type, edge_ind_exp, torch.mean(torch.stack(attention, dim=0), dim=0))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(num_relations='\n",
    "                f'{self.num_relations}, num_bases={self.num_bases})')\n",
    "\n",
    "\n",
    "class LinearAlign(torch.nn.Module):\n",
    "    # Aligns representions to the same dimensionality. Note that this will\n",
    "    # create lazy modules, and as such requires a forward pass in order to\n",
    "    # initialize parameters.\n",
    "    def __init__(self, keys: List[Union[NodeType, EdgeType]],\n",
    "                 out_channels: int):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.lins = torch.nn.ModuleDict()\n",
    "        for key in keys:\n",
    "            self.lins[key2str(key)] = Linear(-1, out_channels, bias=False)\n",
    "\n",
    "    def forward(\n",
    "        self, x_dict: Dict[Union[NodeType, EdgeType], Tensor]\n",
    "    ) -> Dict[Union[NodeType, EdgeType], Tensor]:\n",
    "        \n",
    "        return {key: self.lins[key2str(key)](x) for key, x in x_dict.items()}\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(num_relations={len(self.lins)}, '\n",
    "                f'out_channels={self.out_channels})')\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# These methods are used in order to receive the cumulated sizes of input\n",
    "# dictionaries. We make use of them for creating a unified homogeneous graph\n",
    "# representation, as well as to split the final output data once again.\n",
    "\n",
    "\n",
    "def get_node_offset_dict(\n",
    "    input_dict: Dict[NodeType, Union[Tensor, SparseTensor]],\n",
    "    type2id: Dict[NodeType, int],\n",
    ") -> Dict[NodeType, int]:\n",
    "    cumsum = 0\n",
    "    out: Dict[NodeType, int] = {}\n",
    "    for key in type2id.keys():\n",
    "        out[key] = cumsum\n",
    "        cumsum += input_dict[key].size(0)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_edge_offset_dict(\n",
    "    input_dict: Dict[EdgeType, Union[Tensor, SparseTensor]],\n",
    "    type2id: Dict[EdgeType, int],\n",
    ") -> Dict[EdgeType, int]:\n",
    "    cumsum = 0\n",
    "    out: Dict[EdgeType, int] = {}\n",
    "    for key in type2id.keys():\n",
    "        out[key] = cumsum\n",
    "        value = input_dict[key]\n",
    "        if isinstance(value, SparseTensor):\n",
    "            cumsum += value.nnz()\n",
    "        elif value.dtype == torch.long and value.size(0) == 2:\n",
    "            cumsum += value.size(-1)\n",
    "        else:\n",
    "            cumsum += value.size(0)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# This method computes the edge type of the final homogeneous graph\n",
    "# representation. It will be used in the `HeteroBasisConv` wrapper.\n",
    "\n",
    "\n",
    "def get_edge_type(\n",
    "    input_dict: Dict[EdgeType, Union[Tensor, SparseTensor]],\n",
    "    type2id: Dict[EdgeType, int],\n",
    ") -> Tensor:\n",
    "\n",
    "    inputs = [input_dict[key] for key in type2id.keys()]\n",
    "    outs = []\n",
    "\n",
    "    for i, value in enumerate(inputs):\n",
    "        if value.size(0) == 2 and value.dtype == torch.long:  # edge_index\n",
    "            out = value.new_full((value.size(-1), ), i, dtype=torch.long)\n",
    "        elif isinstance(value, SparseTensor):\n",
    "            out = torch.full((value.nnz(), ), i, dtype=torch.long,\n",
    "                             device=value.device())\n",
    "        else:\n",
    "            out = value.new_full((value.size(0), ), i, dtype=torch.long)\n",
    "        outs.append(out)\n",
    "    \n",
    "    return outs[0] if len(outs) == 1 else torch.cat(outs, dim=0)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# These methods are used to group the individual type-wise components into a\n",
    "# unfied single representation.\n",
    "\n",
    "\n",
    "def group_node_placeholder(input_dict: Dict[NodeType, Tensor],\n",
    "                           type2id: Dict[NodeType, int]) -> Tensor:\n",
    "\n",
    "    inputs = [input_dict[key] for key in type2id.keys()]\n",
    "    return inputs[0] if len(inputs) == 1 else torch.cat(inputs, dim=0)\n",
    "\n",
    "\n",
    "def group_edge_placeholder(\n",
    "    input_dict: Dict[EdgeType, Union[Tensor, SparseTensor]],\n",
    "    type2id: Dict[EdgeType, int],\n",
    "    offset_dict: Dict[NodeType, int] = None,\n",
    ") -> Union[Tensor, SparseTensor]:\n",
    "\n",
    "    inputs = [input_dict[key] for key in type2id.keys()]\n",
    "\n",
    "    if len(inputs) == 1:\n",
    "        return inputs[0]\n",
    "\n",
    "    # In case of grouping a graph connectivity tensor `edge_index` or `adj_t`,\n",
    "    # we need to increment its indices:\n",
    "    elif inputs[0].size(0) == 2 and inputs[0].dtype == torch.long:\n",
    "        if offset_dict is None:\n",
    "            raise AttributeError(\n",
    "                \"Can not infer node-level offsets. Please ensure that there \"\n",
    "                \"exists a node-level argument before the 'edge_index' \"\n",
    "                \"argument in your forward header.\")\n",
    "\n",
    "        outputs = []\n",
    "        for value, (src_type, _, dst_type) in zip(inputs, type2id):\n",
    "            value = value.clone()\n",
    "            value[0, :] += offset_dict[src_type]\n",
    "            value[1, :] += offset_dict[dst_type]\n",
    "            outputs.append(value)\n",
    "\n",
    "        return torch.cat(outputs, dim=-1)\n",
    "\n",
    "    elif isinstance(inputs[0], SparseTensor):\n",
    "        if offset_dict is None:\n",
    "            raise AttributeError(\n",
    "                \"Can not infer node-level offsets. Please ensure that there \"\n",
    "                \"exists a node-level argument before the 'SparseTensor' \"\n",
    "                \"argument in your forward header.\")\n",
    "\n",
    "        # For grouping a list of SparseTensors, we convert them into a\n",
    "        # unified `edge_index` representation in order to avoid conflicts\n",
    "        # induced by re-shuffling the data.\n",
    "        rows, cols = [], []\n",
    "        for value, (src_type, _, dst_type) in zip(inputs, type2id):\n",
    "            col, row, value = value.coo()\n",
    "            assert value is None\n",
    "            rows.append(row + offset_dict[src_type])\n",
    "            cols.append(col + offset_dict[dst_type])\n",
    "\n",
    "        row = torch.cat(rows, dim=0)\n",
    "        col = torch.cat(cols, dim=0)\n",
    "        return torch.stack([row, col], dim=0)\n",
    "\n",
    "    else:\n",
    "        return torch.cat(inputs, dim=0)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# This method is used to split the output tensors into individual type-wise\n",
    "# components:\n",
    "\n",
    "\n",
    "def split_output(\n",
    "    output: Tensor,\n",
    "    offset_dict: Union[Dict[NodeType, int], Dict[EdgeType, int]],\n",
    ") -> Union[Dict[NodeType, Tensor], Dict[EdgeType, Tensor]]:\n",
    "    \n",
    "    # Sometimes an edge index ends up here. Not sure why. TODO: fix --> we should be able to determine which edge belongs\n",
    "    # to which edge type\n",
    "    if type(output) == tuple:\n",
    "        return output\n",
    "    elif output.size(0) == 2:\n",
    "        output = output.T\n",
    "        \n",
    "    cumsums = list(offset_dict.values()) + [output.size(0)]    \n",
    "    sizes = [cumsums[i + 1] - cumsums[i] for i in range(len(offset_dict))]\n",
    "    outputs = output.split(sizes)\n",
    "    \n",
    "    return {key: output for key, output in zip(offset_dict, outputs)}\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def key2str(key: Union[NodeType, EdgeType]) -> str:\n",
    "    key = '__'.join(key) if isinstance(key, tuple) else key\n",
    "    return key.replace(' ', '_').replace('-', '_').replace(':', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76167521-8738-4d34-a165-6a7a7d4bec58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def listwise_loss(scores, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the LambdaRank loss. (assume sigma=1.)\n",
    "    \n",
    "    scores: tensor of size [N, 1] (the output of a neural network), where N = length of <query, document> pairs\n",
    "    labels: tensor of size [N], contains the relevance labels \n",
    "    \n",
    "    returns: a tensor of size [N, 1]\n",
    "    \"\"\"\n",
    "    if labels.size(0) < 2:\n",
    "        return torch.Tensor([[0]])\n",
    "\n",
    "    N = torch.arange(len(scores))\n",
    "    num_docs = len(scores)\n",
    "\n",
    "    sigma = 1\n",
    "\n",
    "\n",
    "    # Calculate lambda_{i, j} for every <i, j>.\n",
    "    S_j = torch.stack([labels] * num_docs)\n",
    "    S_i = S_j.T\n",
    "    #TODO: remove torch.nan_to_num? Changing it to fill_diagonal(0) seemed to break it somehow, even though it shouldnt..\n",
    "    S = torch.nan_to_num((S_i - S_j) / (S_i - S_j).abs())\n",
    "    lamda = (sigma * (0.5 * (1 - S) - (1 / (1 + torch.exp(sigma * (scores - scores.T)))))) #.sum(axis=1).unsqueeze(1)\n",
    "\n",
    "    # Calculate abs(Delta-NDCG) for each ordering <i, j> combination\n",
    "    sorted_ind = torch.flip(scores.argsort(dim=0).flatten(), dims=[0])\n",
    "    sorted_labels = labels[sorted_ind]\n",
    "    ideal_labels = torch.sort(labels)[0].flip(dims=[0])\n",
    "    k = (torch.arange(sorted_labels.shape[0]) + 1).to(device)\n",
    "    DCG_ideal_labels = torch.sum((2**ideal_labels - 1) / torch.log(k + 1)) \n",
    "    doc_id_to_rank = torch.Tensor([(sorted_ind == i).nonzero(as_tuple=True)[0] for i in N]).int()\n",
    "    doc_id_to_label = torch.Tensor([sorted_labels[R_i] for R_i in doc_id_to_rank]).int().to(device)\n",
    "        \n",
    "    #TODO: We always do this stack+transpose, make a function of this? (and can't something like meshgrid() do the same?)\n",
    "    #TODO: Put comments to explain things.\n",
    "    R_j = torch.stack([doc_id_to_rank] * num_docs).to(device)\n",
    "    R_i = R_j.T\n",
    "    label_j = torch.stack([doc_id_to_label] * num_docs).to(device)\n",
    "    label_i = label_j.T\n",
    "    DCG_discount = ((2**label_i - 1) / torch.log(R_i + 2) + (2**label_j - 1) / torch.log(R_j + 2)).to(device)\n",
    "    DCG_gain = ((2**label_j - 1) / torch.log(R_i + 2) + (2**label_i - 1) / torch.log(R_j + 2)).to(device)\n",
    "    delta_NDCG = ((DCG_gain - DCG_discount) / DCG_ideal_labels).abs()\n",
    "\n",
    "    lambda_rank_loss =  (lamda * delta_NDCG).sum(axis=1).unsqueeze(1) \n",
    "    \n",
    "    return lambda_rank_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9618bafb-d427-4fca-904a-ecce286b6a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We embed the textual nodes (candidates and requests) separately at first\n",
    "class text_embedding_layer(torch.nn.Module):\n",
    "    def __init__(self, text_embedding_size=64, text_pooling=\"token\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.e5 = AutoModel.from_pretrained(\"intfloat/multilingual-e5-small\").to(device)\n",
    "        \n",
    "        self.text_pooling = text_pooling\n",
    "                \n",
    "        self.candidate_out = nn.Linear(in_features=384,\n",
    "                                       out_features=text_embedding_size)\n",
    "\n",
    "        self.company_out = nn.Linear(in_features=384,\n",
    "                                     out_features=text_embedding_size)\n",
    "        \n",
    "    def average_pool(self, last_hidden_states, attention_mask):\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "        \n",
    "    def forward(self, x_can, x_req, att_mask_can, att_mask_req):\n",
    "        \n",
    "        # Feed tokens into model\n",
    "        x_candidate = self.e5(x_can, att_mask_can)\n",
    "        x_company = self.e5(x_req, att_mask_req)\n",
    "        \n",
    "        if self.text_pooling == \"token\":\n",
    "            # Create embedding tensor\n",
    "            candidate_embeddings = self.average_pool(x_candidate.last_hidden_state, attention_mask=att_mask_can)\n",
    "            company_embeddings = self.average_pool(x_company.last_hidden_state, attention_mask=att_mask_req)\n",
    "\n",
    "            # normalize embeddings\n",
    "            candidate_embeddings = F.normalize(candidate_embeddings, p=2, dim=1)\n",
    "            company_embeddings = F.normalize(company_embeddings, p=2, dim=1)\n",
    "        elif self.text_pooling == \"sentence\":\n",
    "            # Mean pooling\n",
    "            input_mask_expanded = att_mask_can.unsqueeze(-1).expand(x_candidate.last_hidden_state.size())\n",
    "            sum_embeddings = torch.sum(x_candidate.last_hidden_state * input_mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)  # Avoid division by zero\n",
    "            candidate_embeddings = sum_embeddings / sum_mask\n",
    "            \n",
    "            input_mask_expanded = att_mask_req.unsqueeze(-1).expand(x_company.last_hidden_state.size())\n",
    "            sum_embeddings = torch.sum(x_company.last_hidden_state * input_mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)  # Avoid division by zero\n",
    "            company_embeddings = sum_embeddings / sum_mask\n",
    "\n",
    "        # Run through MLP to match other embedding sizes\n",
    "        x_candidate = self.candidate_out(candidate_embeddings).float()\n",
    "        x_company = self.company_out(company_embeddings).float()\n",
    "        \n",
    "        return x_candidate, x_company  \n",
    "    \n",
    "# Then, we embed all nodes initially\n",
    "class embedding_layer(torch.nn.Module):\n",
    "    def __init__(self, embedding_size=32):\n",
    "        super().__init__()        \n",
    "        \n",
    "        self.conv1 = geom_nn.TransformerConv((-1, -1), embedding_size)\n",
    "        self.conv2 = geom_nn.TransformerConv((-1, -1), embedding_size)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "       \n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "        \n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, embedding_size=64, heads=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.can_pos = geom_nn.GATv2Conv((-1, -1),\n",
    "                                         out_channels=embedding_size,\n",
    "                                         add_self_loops=False,\n",
    "                                         heads=heads,\n",
    "                                         concat=False)\n",
    "        \n",
    "        self.can_neg = geom_nn.GATv2Conv((-1, -1),\n",
    "                                         out_channels=embedding_size,\n",
    "                                         add_self_loops=False,\n",
    "                                         heads=heads,\n",
    "                                         concat=False)\n",
    "        self.com_pos = geom_nn.GATv2Conv((-1, -1),\n",
    "                                         out_channels=embedding_size,\n",
    "                                         add_self_loops=False,\n",
    "                                         heads=heads,\n",
    "                                         concat=False)\n",
    "\n",
    "        self.com_neg = geom_nn.GATv2Conv((-1, -1),\n",
    "                                         out_channels=embedding_size,\n",
    "                                         add_self_loops=False,\n",
    "                                         heads=heads,\n",
    "                                         concat=False)\n",
    "        \n",
    "        # Different batch norm for each GATv2 output, as it includes learned parameters\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(embedding_size)\n",
    "        self.batch_norm2 = torch.nn.BatchNorm1d(embedding_size)\n",
    "        self.batch_norm3 = torch.nn.BatchNorm1d(embedding_size)\n",
    "        self.batch_norm4 = torch.nn.BatchNorm1d(embedding_size)\n",
    "\n",
    "        self.dense_can = nn.Linear(in_features=embedding_size,\n",
    "                                   out_features=heads)\n",
    "    \n",
    "        self.dense_com = nn.Linear(in_features=embedding_size,\n",
    "                                   out_features=heads)\n",
    "    \n",
    "        \n",
    "        self.elu = nn.ELU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, edge_index):            \n",
    "        ### Positive candidate-side attention\n",
    "        x_can_pos, can_pos_exp = self.can_pos(x, \n",
    "                                              edge_index.long(), \n",
    "                                              return_attention_weights=True)\n",
    "        \n",
    "        ### Negative candidate-side attention        \n",
    "        x_can_neg, can_neg_exp = self.can_neg(x_can_pos, \n",
    "                                              edge_index.long(), \n",
    "                                              return_attention_weights=True)\n",
    "\n",
    "        ### Positive company-side attention\n",
    "        # We flip the edge index to distinguish this as a 'company-side' graph\n",
    "        x_com_pos, com_pos_exp = self.com_pos(x * -1, \n",
    "                                              edge_index[[1, 0]].long(), \n",
    "                                              return_attention_weights=True)\n",
    "\n",
    "        ### Negative company-side attention\n",
    "        x_com_neg, com_neg_exp = self.com_neg(x_com_pos, \n",
    "                                              edge_index[[1, 0]].long(), \n",
    "                                              return_attention_weights=True)\n",
    "        \n",
    "        # Edge embedding\n",
    "        e_im_can = self.sigmoid(\n",
    "                            torch.sum(\n",
    "                                torch.stack([can_pos_exp[2], \n",
    "                                             can_neg_exp[2]], \n",
    "                                      dim=0), \n",
    "                                dim=0)\n",
    "                    )        \n",
    "        \n",
    "        e_im_com = self.sigmoid(\n",
    "                            torch.sum(\n",
    "                                torch.stack([com_pos_exp[2], \n",
    "                                             com_neg_exp[2]], \n",
    "                                        dim=0), \n",
    "                                dim=0)\n",
    "                    )\n",
    "        \n",
    "        x_can_pos = self.batch_norm1(x_can_pos)\n",
    "        x_can_neg = self.batch_norm2(x_can_neg)\n",
    "        \n",
    "        x_com_pos = self.batch_norm3(x_com_pos)\n",
    "        x_com_neg = self.batch_norm4(x_com_neg)\n",
    "         \n",
    "        # Mean pool\n",
    "        x_can = torch.mean(torch.stack([self.elu(x_can_pos), \n",
    "                                        self.elu(x_can_neg)]), dim=0)\n",
    "        \n",
    "        x_com = torch.mean(torch.stack([self.elu(x_com_pos), \n",
    "                                        self.elu(x_com_neg)]), dim=0)\n",
    "            \n",
    "        # Node embedding\n",
    "        v_im_can = self.dense_can(x_can).relu()\n",
    "        v_im_com = self.dense_com(x_com).relu()\n",
    "        \n",
    "        return x_can, x_com, v_im_can, v_im_com, e_im_can, e_im_com,\\\n",
    "               can_pos_exp, can_neg_exp, com_pos_exp, com_neg_exp\n",
    "    \n",
    "class OKRA(torch.nn.Module):\n",
    "    def __init__(self, data, typings, embedding_size=64, text_embedding_size=64, pooling_method=\"mean\", text_pooling=\"token\", heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.typings = typings\n",
    "        self.num_heads = heads\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.pooling = {\n",
    "            \"mean\": lambda x, dim: torch.mean(x, dim=dim),\n",
    "            \"sum\": lambda x, dim: torch.sum(x, dim=dim),\n",
    "            # Only return the values for max pooling, ignoring the indices\n",
    "            \"max\": lambda x, dim: torch.max(x, dim=dim)[0]\n",
    "        }[pooling_method]\n",
    "        \n",
    "        self.text_embedder = text_embedding_layer(text_embedding_size=text_embedding_size, text_pooling=text_pooling)\n",
    "\n",
    "        self.embedder = embedding_layer(embedding_size=embedding_size)\n",
    "        self.embedder = to_hetero(self.embedder, data.metadata(), aggr='sum')\n",
    "\n",
    "        self.gnn = GNN(embedding_size=embedding_size, heads=heads)\n",
    "        self.gnn = to_hetero_with_bases(self.gnn, data.metadata(), num_bases=3)\n",
    "        \n",
    "        # Each embedding is the size heads * embedding_size * 3, as there is one heads * embedding_size embedding for each (head node, tail node, sub-graph)\n",
    "        self.mlp_candidate = nn.Linear(in_features=heads * embedding_size * 3,\n",
    "                                       out_features=1)\n",
    "        \n",
    "        self.mlp_company = nn.Linear(in_features=heads * embedding_size * 3,\n",
    "                                     out_features=1)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # Embed textual features       \n",
    "        x_candidate, x_request = self.text_embedder(data.x_dict[\"candidate\"], data.x_dict[\"request\"], data[\"candidate\"].att_mask, data[\"request\"].att_mask)\n",
    "        \n",
    "        # Store the textual embeddings along with the rest of the graph\n",
    "        data.x_dict[\"candidate\"] = x_candidate\n",
    "        data.x_dict[\"request\"] = x_request\n",
    "\n",
    "        # Embed the graph as a whole\n",
    "        embedded_data = self.embedder({k: v.float() for k, v in data.x_dict.items()}, data.edge_index_dict)\n",
    "       \n",
    "        # Run the embedded graph through the GNN\n",
    "        x_can, x_com, v_im_can1, v_im_com1, e_im_can, e_im_com, \\\n",
    "        can_pos_exp, can_neg_exp, com_pos_exp, com_neg_exp = self.gnn(embedded_data, \n",
    "                                                                      data.edge_index_dict)\n",
    "        \n",
    "        # Combine the attention with the values, once per head, for both the candidate and company side\n",
    "        h_can = defaultdict(lambda : torch.Tensor([]).to(device))\n",
    "        h_com = defaultdict(lambda : torch.Tensor([]).to(device))\n",
    "    \n",
    "        # Store each node as a combination of its head embeddings\n",
    "        for typing in self.typings:\n",
    "            for k in range(self.num_heads):\n",
    "                if typing in x_can:\n",
    "                    h_can[typing] = torch.cat([h_can[typing], (x_can[typing].T * v_im_can1[typing][:,k]).T], dim=1)\n",
    "                else:\n",
    "                    h_can[typing] = torch.cat([h_can[typing], torch.zeros_like(h_can[list(h_can.keys())[0]].T)])\n",
    "                \n",
    "                if typing in x_com:\n",
    "                    h_com[typing] = torch.cat([h_com[typing], (x_com[typing].T * v_im_com1[typing][:,k]).T], dim=1)\n",
    "                else:\n",
    "                    h_com[typing] = torch.cat([h_com[typing], torch.zeros_like(h_com[list(h_com.keys())[0]].T)])\n",
    "                            \n",
    "        # Each sub-graph gets its own embedding\n",
    "        sub_graphs_candidate = defaultdict(list)\n",
    "        sub_graphs_company = defaultdict(list)\n",
    "        \n",
    "        # Additionally, the head and tail node (candidate and vacancy) get stored separately as well\n",
    "        main_nodes_candidate = defaultdict(list)\n",
    "        main_nodes_company = defaultdict(list)\n",
    "        \n",
    "\n",
    "                                               \n",
    "        # Find the sub-graph of each node in the embedding, and add it to the corresponding list\n",
    "        for typing in self.typings:\n",
    "            for i, emb in enumerate(h_can[typing]):            \n",
    "                # Some subgraphs do not have all data types (e.g., a graph might not include any education nodes)\n",
    "                if data[typing]:\n",
    "                    # Find the sub-graph the current node belongs to\n",
    "                    current_node_id = int(data[typing].unique_node_id[i].item())\n",
    "                                        \n",
    "                    # We were working with a dummy node\n",
    "                    if current_node_id == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    sg = int(data[typing].sub_graph[i].item())\n",
    "                    \n",
    "                    # If our node is a head/tail node, store it accordingly\n",
    "                    if (in_head := (current_node_id in data.head_nodes[0])) or (in_tail := (current_node_id in data.tail_nodes[0])):                        \n",
    "                        main_nodes_candidate[sg].append(emb)\n",
    "                        main_nodes_company[sg].append(h_com[typing][i])\n",
    "                    \n",
    "                    # Add its candidate embedding to its sub-graph embedding\n",
    "                    sub_graphs_candidate[sg].append(emb.unsqueeze(0))\n",
    "\n",
    "                    # Do the same on the company side\n",
    "                    sub_graphs_company[sg].append(h_com[typing][i].unsqueeze(0))               \n",
    "\n",
    "        # Finally, pool every graph embedding (so the final embedding is the mean of all of the nodes)\n",
    "        for sg in sub_graphs_candidate.keys():            \n",
    "            sub_graphs_candidate[sg] = self.pooling(torch.stack(sub_graphs_candidate[sg]).squeeze(1), dim=0)\n",
    "            sub_graphs_company[sg] = self.pooling(torch.stack(sub_graphs_company[sg]).squeeze(1), dim=0)\n",
    "                                        \n",
    "            # Add the head and tail node to the full embedding\n",
    "            sub_graphs_candidate[sg] = torch.cat([torch.cat(main_nodes_candidate[sg], dim=0).squeeze(), sub_graphs_candidate[sg]])\n",
    "            sub_graphs_company[sg] = torch.cat([torch.cat(main_nodes_company[sg], dim=0).squeeze(), sub_graphs_company[sg]])\n",
    "                        \n",
    "        # Stack all the sub-graph embeddings into a single matrix, both candidate- and company-sided\n",
    "        sub_graphs_candidate = torch.stack([i[1] for i in sorted(sub_graphs_candidate.items())], dim=0)\n",
    "        sub_graphs_company = torch.stack([i[1] for i in sorted(sub_graphs_company.items())], dim=0)\n",
    "                \n",
    "        # Make predictions based on the sub-graph embeddings\n",
    "        y_candidate = torch.clamp(self.mlp_candidate(sub_graphs_candidate), min=-100, max=100)\n",
    "        y_company = torch.clamp(self.mlp_company(sub_graphs_company), min=-100, max=100)\n",
    "        \n",
    "        # Final prediction is the harmonic mean of the candidate- and company-sided prediction\n",
    "        y_pred = 2 * ((y_candidate * y_company) / (y_candidate + y_company))\n",
    "        \n",
    "        # The harmonic mean of X and 0 should be 0, not nan\n",
    "        y_pred = torch.nan_to_num(y_pred).squeeze()\n",
    "        \n",
    "        return y_pred, y_candidate, y_company, (can_pos_exp, can_neg_exp, com_pos_exp, com_neg_exp, v_im_can1, v_im_com1, e_im_can, e_im_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76aa331-0619-43d5-89e3-b831fdfd1881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, trainloader, valloader, epochs=10):\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(trainloader):  \n",
    "\n",
    "            # Make prediction\n",
    "            y_pred, y_candidate, y_company, explanation = model(data.detach().clone().to(device))\n",
    "\n",
    "            print(\"                                                                                                                    \", end=\"\\r\")\n",
    "            print(f\"Epoch: {epoch + 1}/{epochs}, batch (train): {i + 1}/{len(trainloader)}, y_pred mean: {y_pred.mean()}\", end=\"\\r\")\n",
    "\n",
    "            # Calculate and backpropagate gradients\n",
    "            optimizer.zero_grad()\n",
    "            lambda_i = listwise_loss(y_pred, data.y.to(device))\n",
    "            torch.autograd.backward(y_pred, lambda_i.squeeze())\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log loss in wandb\n",
    "            wandb.log({\"loss\": lambda_i.squeeze().mean()})\n",
    "\n",
    "            # Calculate nDCG score of current batch\n",
    "            ndcg_scores.append(ndcg_score(data.y.unsqueeze(0).cpu(), \n",
    "                                          y_pred.unsqueeze(0).detach().cpu(), k=10))\n",
    "            \n",
    "        # Log epoch-level metrics to WandB\n",
    "        wandb.log({\"Epoch\": epoch+1, \"Training nDCG\": np.mean(ndcg_scores)})\n",
    "        print(f\"\\n\\nTraining nDCG: {np.mean(ndcg_scores)}\\n\")\n",
    "        ndcg_scores = []\n",
    "        \n",
    "        # Evaluate model\n",
    "        ndcg_val = val_loop(model, valloader)\n",
    "        print(f\"\\nValidation nDCG: {np.mean(ndcg_val)}\\n\")\n",
    "        wandb.log({\"Validation nDCG\": np.mean(ndcg_val)})\n",
    "        \n",
    "    # Return nDCG of final trained model\n",
    "    return ndcg_val\n",
    "\n",
    "def val_loop(model, valloader):\n",
    "    ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data_val in enumerate(valloader):\n",
    "            print(f\"Batch (val): {i + 1}/{len(valloader)}\", end=\"\\r\")\n",
    "            \n",
    "            # Make prediction\n",
    "            y_pred_val, y_candidate_val, y_company_val, explanation_val = model(data_val.detach().clone().to(device))\n",
    "             \n",
    "            # Calculate nDCG score of current batch   \n",
    "            ndcg_scores.append(ndcg_score(data_val.y.unsqueeze(0).cpu(), \n",
    "                                           y_pred_val.unsqueeze(0).detach().cpu(), k=10))\n",
    "            \n",
    "    return ndcg_scores\n",
    "\n",
    "\n",
    "def optimize_model(trial, trainloader, valloader, epochs=10):\n",
    "    \n",
    "    # Set up WandB integration\n",
    "    wandb.init(project=\"okra\", job_type=\"optimize\")\n",
    "    \n",
    "    # Data.metadata() is needed to initialize the heterodata\n",
    "    data = next(iter(trainloader))\n",
    "\n",
    "    # Search space    \n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
    "    text_embedding_size = trial.suggest_categorical('text_embedding_size', [32, 128, 256])\n",
    "    embedding_size = trial.suggest_categorical('embedding_size', [32, 128, 256])\n",
    "    pooling_method = trial.suggest_categorical('pooling_method', [\"mean\", \"max\", \"sum\"])\n",
    "    text_pooling = trial.suggest_categorical('text_pooling', [\"token\", \"sentence\"])             \n",
    "                                        \n",
    "    # Configuration for WandB\n",
    "    config = {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"text_embedding_size\": text_embedding_size,\n",
    "        \"embedding_size\": embedding_size,\n",
    "        \"pooling_method\": pooling_method,\n",
    "        \"text_pooling\": text_pooling\n",
    "    }\n",
    "    wandb.config.update(config)\n",
    "\n",
    "    print(f\"\"\"\\nConfig:\\n- learning_rate = {learning_rate}\\n- text_embedding_size = {text_embedding_size}\\n- embedding_size = {embedding_size}\\n- pooling_method = {pooling_method}\\n- text_pooling = {text_pooling}\\n\"\"\")\n",
    "    \n",
    "    # All the different node types\n",
    "    typings = [\"candidate\", \"request\", \"function_name\", \"isco_code\", \n",
    "               \"education\", \"language\", \"license\", \"skill\", \"company_name\", \n",
    "               \"function_id\", \"isco_level\", \"workgroup\", \"klass\", \"literal\"]\n",
    "    \n",
    "    # Initiate the model (number of heads is locked, as that is required for the multi-explanation component to function)\n",
    "    model = OKRA(data,\n",
    "                 typings,\n",
    "                 text_embedding_size=text_embedding_size,\n",
    "                 text_pooling=text_pooling,\n",
    "                 embedding_size=embedding_size,\n",
    "                 pooling_method=pooling_method,\n",
    "                 heads=4).to(device)\n",
    "\n",
    "    # Configure Adam\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    start_time = time.time() \n",
    "    # Train and evaluate model\n",
    "    ndcg_scores_val = train_loop(model, optimizer, trainloader, valloader, epochs=epochs)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Training for {epochs} epochs took {end_time - start_time} seconds ({(end_time - start_time) / epochs} seconds per epoch)\")\n",
    "    \n",
    "    return np.mean(ndcg_scores_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14bf416-14a1-44aa-bc9f-15e11240a9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_wrapper(trainloader, valloader):\n",
    "    def objective(trial):\n",
    "        return optimize_model(trial, trainloader, valloader, epochs=6)\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b008f-5ea5-4644-be5f-10e27deda5f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "gc.collect()\n",
    "\n",
    "# Hide user/future warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# We need to provide trainloader and valloader to the training/validation loop\n",
    "wrapped_objective = objective_wrapper(trainloader, valloader)\n",
    "\n",
    "# Start optimization\n",
    "study.optimize(wrapped_objective, n_trials=32)  \n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "\n",
    "with open(\"okra_results.txt\", \"w+\") as f:\n",
    "    json.dump(study.best_trial.params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0310c6-cc0b-43bf-9231-9ce25df26ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc0b78-b1d6-49fc-a5af-ff57cdf24a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb58510-ff9e-4cef-8e1c-439cf3812c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
