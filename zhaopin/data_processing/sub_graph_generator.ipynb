{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c00f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import pickle\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421ba29-78cf-4d7f-8d93-036a328268ca",
   "metadata": {},
   "source": [
    "# Load interaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = pd.read_csv(\"../source_data/actions_updated.csv\")[[\"user_id\", \"jd_no\", \"browsed\", \"delivered\", \"satisfied\"]]\n",
    "actions[\"label\"] = actions[[\"browsed\", \"delivered\", \"satisfied\"]].sum(axis=1)\n",
    "actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec94ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only consider candidates with at least 5 matching vacancies in the dataset\n",
    "# This not only saves time, but also improves results later on\n",
    "candidate_counts = actions[actions[\"label\"] > 0].groupby(\"user_id\")[\"jd_no\"].count()\n",
    "candidate_list = candidate_counts[candidate_counts >= 5].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76311520-d4c0-48f4-8e4b-608971e693c1",
   "metadata": {},
   "source": [
    "# Load KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01214381",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "with open(\"kg.edgelist\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f.readlines()):\n",
    "        \n",
    "        if \"err:error\" in line:\n",
    "            continue\n",
    "            \n",
    "        s, p, o = eval(line)\n",
    "        G.add_edge(s, o, edge_type=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neighbors of each node (for quicker retrieval later on) \n",
    "all_neighbors = {}\n",
    "\n",
    "H = G.to_undirected()\n",
    "\n",
    "for n in tqdm(G.nodes):\n",
    "    all_neighbors[n] = set(H.neighbors(n))\n",
    "    \n",
    "all_neighbors = {k: {i for i in v if not pd.isna(i)} for k, v in all_neighbors.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb364da1-2117-490e-be05-f58412cb031a",
   "metadata": {},
   "source": [
    "# Load and clean textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e352f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = pd.read_csv(\"../source_data/cv_data.csv\")[[\"user_id\", \"experience\"]]\n",
    "df_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71213ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(df_cv.itertuples(), total=4500):\n",
    "    \n",
    "    if type(row[2]) == str:\n",
    "        cv = re.sub(\"\\n+\", \" \\n \", row[2]).lower()\n",
    "    else:\n",
    "        cv = \"\"\n",
    "    \n",
    "    nx.set_node_attributes(H, {f\"zne:{row[1]}\": cv}, \"CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ddaaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jd = pd.read_csv(\"../source_data/jd_data.csv\")[[\"jd_no\", \"jd_title\", \"job_description\"]]\n",
    "df_jd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(df_jd.itertuples(), total=265690):\n",
    "    \n",
    "    if type(row[2]) == str or type(row[3]) == str:\n",
    "        cv = re.sub(\"\\n+\", \" \\n \", row[2] + row[3]).lower()\n",
    "    else:\n",
    "        cv = \"\"\n",
    "    \n",
    "    nx.set_node_attributes(H, {f\"zne:{row[1]}\": cv}, \"CV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748cfb16-b67f-4b78-82af-f5fe213a70b6",
   "metadata": {},
   "source": [
    "# Perform k random walks over the KG to find candidate-vacancy sub-graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb491857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_walk(G, a, b, all_neighbors, k=6, walks=100):\n",
    "    sub_graph = []\n",
    "            \n",
    "    # Number of walks\n",
    "    for _ in range(walks):\n",
    "        path = ()\n",
    "        \n",
    "        visited = set()\n",
    "        \n",
    "        prev_node = a\n",
    "        old = None\n",
    "        \n",
    "        # Length of each walk\n",
    "        for _ in range(k):\n",
    "            # Choose a random neighbor of our current node\n",
    "            candidates = all_neighbors[prev_node] # if prev_node in all_neighbors else set(G.neighbors(prev_node))\n",
    "                \n",
    "            # Don't backtrack unless absolutely necessary\n",
    "            if old and len(candidates) > 1:\n",
    "                candidates = candidates - set([old])\n",
    "            \n",
    "            # If we can reach the target from the current node, \n",
    "            # do so, as long as that wouldn't create a duplicate path\n",
    "            if b in candidates and (prev_node, b) not in set(sub_graph):\n",
    "                next_node = b\n",
    "            else:\n",
    "                if candidates:\n",
    "                    next_node = np.random.choice(list(candidates))\n",
    "                    \n",
    "                    if next_node in visited:\n",
    "                        continue\n",
    "                    else:\n",
    "                        visited.add(next_node)                    \n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            path += (prev_node, next_node),\n",
    "\n",
    "            # Update\n",
    "            old = prev_node\n",
    "            prev_node = next_node\n",
    "            \n",
    "            # If we found the target, store\n",
    "            if next_node == b:\n",
    "                sub_graph.extend(path)\n",
    "                break\n",
    "                \n",
    "    sg = set(sub_graph)\n",
    "    sg -= {(a, b)}\n",
    "    sg -= {(b, a)}\n",
    "                \n",
    "    H = G.edge_subgraph(sg)\n",
    "               \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsons(G, all_neighbors, k=10, walks=50):\n",
    "        \n",
    "    error = \"\"\n",
    "        \n",
    "    for i, candidate in tqdm(enumerate(candidate_list), total=len(candidate_list)):\n",
    "        # Find all misses for the current candidate - these can either be explicit or implicit\n",
    "        # Store only the first 15, as we do not need, for example, 456 matching vacancies for a single candidate\n",
    "        if f\"{candidate}.csv\" in os.listdir(\"./ground_truth\"):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            hits = actions[(actions[\"user_id\"] == candidate) & (actions[\"label\"] > 0)][[\"jd_no\", \"label\"]][:15]\n",
    "\n",
    "            n_hits = len(hits)\n",
    "\n",
    "            # Select 30-n_hits misses, so we have 30 (non-)matching vacancies per candidate\n",
    "            misses = actions[((actions[\"user_id\"] == candidate) & \\\n",
    "                              (actions[\"label\"] <= 0)) | \\\n",
    "                             ((actions[\"user_id\"] != candidate))][[\"jd_no\", \"label\"]].sample(30-n_hits)\n",
    "\n",
    "            record = \"\"\n",
    "\n",
    "            missed_graphs = defaultdict(lambda : defaultdict(dict))\n",
    "            hit_graphs = defaultdict(lambda : defaultdict(dict))\n",
    "\n",
    "            for miss in misses.itertuples():\n",
    "                graph = k_walk(H, f\"zne:{candidate}\", f\"zne:{miss[1]}\", all_neighbors, k=k, walks=walks)\n",
    "\n",
    "                if graph:\n",
    "                    record += f\"{candidate},{miss[1]},{miss[2] if miss[2] <= 0 else 0}\\n\"    \n",
    "                    missed_graphs[miss[1]] = nx.node_link_data(graph)\n",
    "\n",
    "            for hit in hits.itertuples():\n",
    "                graph = k_walk(H, f\"zne:{candidate}\", f\"zne:{miss[1]}\", all_neighbors, k=k, walks=walks)\n",
    "\n",
    "                if graph:\n",
    "                    record += f\"{candidate},{hit[1]},{miss[2]}\\n\"    \n",
    "                    hit_graphs[hit[1]] = nx.node_link_data(graph)\n",
    "\n",
    "            with open(f\"misses/{candidate}.json\", \"w\") as f1:\n",
    "                json.dump(missed_graphs, f1)\n",
    "\n",
    "            with open(f\"hits/{candidate}.json\", \"w\") as f1:\n",
    "                json.dump(hit_graphs, f1)\n",
    "\n",
    "            with open(f\"ground_truth/{candidate}.csv\", \"w\") as f1:\n",
    "                f1.write(record)\n",
    "        except Exception as e:\n",
    "            error = str(e)\n",
    "            \n",
    "        with open(\"log.txt\", \"a\") as f:\n",
    "            if error:\n",
    "                f.write(f\"{datetime.datetime.now()} - {i}/{len(candidate_list)} - error: {error}\\n\")\n",
    "                error = \"\"\n",
    "            else:\n",
    "                f.write(f\"{datetime.datetime.now()} - {i}/{len(candidate_list)} - successfully written\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40129bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_jsons(H, all_neighbors, k=7, walks=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c2862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
