{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace34313-5324-4af2-a37a-f351e531d16d",
   "metadata": {},
   "source": [
    "### Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5039a8-b913-4ad5-83dd-e631fa261ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import optuna \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db14cac-36a4-464b-b81b-2585aa5c8084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "li = []\n",
    "\n",
    "# Retrieve ground truth values for each candidate-vacancy pair\n",
    "for truth in os.listdir(\"./ground_truth\"):\n",
    "    if \".csv\" in truth:\n",
    "        df = pd.read_csv(f\"./ground_truth/{truth}\", header=None)\n",
    "        li.append(df)\n",
    "        \n",
    "        \n",
    "truths = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2610cd1c-287a-43fb-b386-476393d49ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "truth_dict = {key1: dict(group[[1, 2]].values) for key1, group in truths.groupby(0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe70b336-79b5-49c3-b580-59413fb8b830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "truth_dict = {k: v for k, v in truth_dict.items() if not all([i <= 0 for i in v.values()])}\n",
    "truth_dict = {k: {j: graph for j, graph in v.items() if type(j) == str} for k, v in truth_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c5190-f253-4c93-9511-7fe2974a5c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(truth_dict), np.mean([len(v) for v in truth_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7b9fc-eaa6-401b-be3b-844473a57ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./source_data/cv_vacancy_data.tsv\", sep=\"\\t\")[[\"user_id\", \"experience\", \"jd_no\", \"full_text\", \"label\"]]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027b0af-afb6-419c-b347-48b5ec22acca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relevant_candidates = set(truth_dict.keys())\n",
    "relevant_vacancies = [set(v.keys()) for _, v in truth_dict.items()]\n",
    "relevant_vacancies = set([item for sublist in relevant_vacancies for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b265f5e-e951-4be3-9f92-402dd6fc9c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_data = {}\n",
    "req_data = {}\n",
    "\n",
    "for row in data.itertuples():   \n",
    "        if type(row[1]) == str and row[1] not in cv_data and f\"{row[1]}\" in relevant_candidates:\n",
    "\n",
    "            cv = row[2]\n",
    "            if not type(cv) == str:\n",
    "                cv = \"\"\n",
    "\n",
    "            cv_data[row[1]] = re.sub(r\"\\s+\", \" \", re.sub(\"\\n+\", \"\\n \", re.sub(r\"\\W\", \" \", cv))).lower()\n",
    "\n",
    "        if type(row[3]) == str and (row[3] not in req_data) and f\"{row[3]}\" in relevant_vacancies:\n",
    "\n",
    "            jd = row[4]\n",
    "            if not type(jd) == str:\n",
    "                jd = \"\"\n",
    "            \n",
    "            req_data[row[3]] = re.sub(r\"\\s+\", \" \", re.sub(\"\\n+\", \"\\n \", re.sub(r\"\\W\", \" \", jd))).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18476e-b342-433e-a120-84800be4f4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3afa294-ce99-478c-b08b-ce9ea27dd79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_cv_len = []\n",
    "avg_req_len = []\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-small\")\n",
    "\n",
    "for cv in cv_data.values():\n",
    "    tokens = tokenizer(cv, add_special_tokens=True, return_tensors='pt')[\"input_ids\"]\n",
    "    avg_cv_len.append(len(tokens[0]))\n",
    "\n",
    "print(f\"Average tokens per CV: {np.mean(avg_cv_len)} ({np.std(avg_cv_len)})\")\n",
    "\n",
    "\n",
    "for req in req_data.values():\n",
    "    tokens = tokenizer(req, add_special_tokens=True, return_tensors='pt')[\"input_ids\"]\n",
    "    avg_req_len.append(len(tokens[0]))\n",
    "\n",
    "print(f\"Average tokens per request: {np.mean(avg_req_len)} ({np.std(avg_req_len)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfaf57e-16c9-4521-9055-d73f49f7ce8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_slice = list(truth_dict.items())[:int(len(truth_dict) * 0.8)]\n",
    "val_slice = list(truth_dict.items())[int(len(truth_dict) * 0.8):int(len(truth_dict) * 0.9)]\n",
    "test_slice = list(truth_dict.items())[int(len(truth_dict) * 0.9):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c74f82-c039-4150-8d37-c54ba872373f",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928f0f8-4b9f-4ebd-88ad-60b9dcf77782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace02d4-bfbd-4a90-a98b-2c0cde88dc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The first 80% of the data will be used to train the TF-IDF vectorizer\n",
    "training_set = []\n",
    "\n",
    "for candidate, vacancies in training_slice:\n",
    "    training_set.append(cv_data[candidate])\n",
    "    \n",
    "    for vacancy in vacancies:\n",
    "        training_set.append(req_data[vacancy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b97977-bc8d-4608-9e4a-6ca3eb414809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The remaining 80% will be used to evaluate its performance on unseen data\n",
    "val_set = []\n",
    "\n",
    "for candidate, vacancies in val_slice:\n",
    "    batch = []\n",
    "    \n",
    "    batch.append(cv_data[candidate])\n",
    "    \n",
    "    for vacancy, label in vacancies.items():\n",
    "        batch.append((req_data[vacancy], label if label >= 0 else 0))\n",
    "        \n",
    "    val_set.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062203ea-d81a-42b6-b779-ecd5e6848fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The remaining 80% will be used to evaluate its performance on unseen data\n",
    "val_set = []\n",
    "\n",
    "for candidate, vacancies in val_slice:\n",
    "    batch = []\n",
    "    \n",
    "    batch.append(cv_data[candidate])\n",
    "    \n",
    "    for vacancy, label in vacancies.items():\n",
    "        batch.append((req_data[vacancy], label if label >= 0 else 0))\n",
    "        \n",
    "    val_set.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ba755-e6bc-4351-9742-d6f117b7b26e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_model = vectorizer.fit(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6cdde-e75b-4f42-9338-2af27d7e2636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndcg_scores = []\n",
    "\n",
    "# Embed each CV and its corresponding vacancies using the model, calculate cosine similarity\n",
    "# and evaluate using nDCG\n",
    "for batch in tqdm(val_set):\n",
    "    \n",
    "    ground_truth = []\n",
    "    y_pred = []\n",
    "    \n",
    "    cv_emb = tf_idf_model.transform([batch[0]])\n",
    "    \n",
    "    for vacancy, label in batch[1:]:        \n",
    "        req_emb = tf_idf_model.transform([vacancy])\n",
    "        \n",
    "        ground_truth.append(label)\n",
    "        y_pred.append(cosine_similarity(cv_emb, req_emb)[0][0])\n",
    "    \n",
    "    ground_truth = np.array(ground_truth)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    ndcg_scores.append(ndcg_score([ground_truth], [y_pred], k=10))\n",
    "    \n",
    "print(\"nDCG of TF-IDF model:\", np.mean(ndcg_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bab3b7-d97c-463f-a6dd-e106cdd1a8bc",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1b1db3-ad65-4111-9e75-53ce5ba86ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndcg_scores = []\n",
    "\n",
    "# Embed each CV and its corresponding vacancies using the model, calculate cosine similarity\n",
    "# and evaluate using nDCG\n",
    "for batch in tqdm(val_set):\n",
    "    \n",
    "    ground_truth = []\n",
    "    y_pred = []\n",
    "    \n",
    "    cv_emb = np.random.random(350)\n",
    "    \n",
    "    for vacancy, label in batch[1:]:        \n",
    "        req_emb = np.random.random(350)\n",
    "        \n",
    "        ground_truth.append(label)\n",
    "        y_pred.append(cosine_similarity([cv_emb], [req_emb])[0][0])\n",
    "    \n",
    "    ground_truth = np.array(ground_truth)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    ndcg_scores.append(ndcg_score([ground_truth], [y_pred], k=10))\n",
    "    \n",
    "print(\"nDCG of random model:\", np.mean(ndcg_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d3d39-9241-488f-a7f4-b5c990a07605",
   "metadata": {},
   "source": [
    "# D2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9f40f-6e4b-4a5f-86c2-0740911e58e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q gensim optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ee6b1-d00d-4fac-b18f-e709d071b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6fceb-a1ea-4ea5-8f65-0b1ee2cbbd1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import optuna\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from scipy.linalg import triu\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a4b69-f018-4167-93d2-b378449edb34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(gensim.utils.simple_preprocess(doc), [i]) for i, doc in enumerate(training_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c28fc-16e3-4b37-970f-d36c515a0857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "def train_d2v(trial, documents):\n",
    "\n",
    "     # Search space\n",
    "    min_count = trial.suggest_categorical('min_count', [0, 1, 2, 5])\n",
    "    window_size = trial.suggest_categorical('window_size', [2, 5, 10, 20])\n",
    "    vector_size = trial.suggest_categorical('vector_size', [16, 32, 128, 256])\n",
    "    epochs = trial.suggest_categorical('epochs', [5, 20, 40, 100])\n",
    "    \n",
    "    print(f\"Starting training\\nConfig: vector_size: {vector_size}, window_size: {window_size}, min_counts: {min_count}, epochs: {epochs}\")\n",
    "\n",
    "    model = Doc2Vec(vector_size=vector_size, window=window_size, min_count=min_count, epochs=epochs, workers=4)\n",
    "    model.build_vocab(documents)\n",
    "    model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for batch in val_set:\n",
    "        ground_truth = []\n",
    "        y_pred = []\n",
    "\n",
    "        cv_emb = model.infer_vector(gensim.utils.simple_preprocess(batch[0]))\n",
    "\n",
    "        for vacancy, label in batch[1:]:\n",
    "            vacancy_emb = model.infer_vector(gensim.utils.simple_preprocess(vacancy))\n",
    "            ground_truth.append(label)\n",
    "            y_pred.append(cosine_similarity([cv_emb], [vacancy_emb])[0][0])\n",
    "\n",
    "        ndcg_scores.append(ndcg_score([ground_truth], [y_pred], k=10))\n",
    "\n",
    "    score = np.mean(ndcg_scores)\n",
    "    print(f\"score: {score}\")\n",
    "    print()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ef00a-799e-4b33-b174-0b239b78c0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_wrapper(documents):\n",
    "    def objective(trial):\n",
    "        return train_d2v(trial, documents)\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed6cf7-6d93-4f2a-aaf5-329404b25081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# We need to provide trainloader and valloader to the training/validation loop\n",
    "wrapped_objective = objective_wrapper(documents)\n",
    "\n",
    "# Start optimization\n",
    "study.optimize(wrapped_objective, n_trials=12)  \n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "\n",
    "with open(\"d2v_results.txt\", \"w+\") as f:\n",
    "    json.dump(study.best_trial.params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9434a9-6383-4d33-92f2-782c669b7c2d",
   "metadata": {},
   "source": [
    "# BERT (e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c5483a-e02a-492b-9e40-00de9e91f833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers wandb peft optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17066f-82d2-4372-9775-b7f0e9e22f03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import wandb\n",
    "import warnings\n",
    "import optuna\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d80c1-6ffa-4411-a636-eba257c36eda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f3b57-b118-4e4f-b5d9-28a67eed6d35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenDataLoader(Dataset):\n",
    "    def __init__(self, truth_dict, cv_data, req_data, query_size=512, batch_size=32):\n",
    "        self.ground_truths = list(truth_dict.items())\n",
    "        self.cv_texts = cv_data\n",
    "        self.req_texts = req_data\n",
    "        \n",
    "        self.query_size = query_size\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-base\")\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        # Adjust the length to account for the number of batches based on candidates\n",
    "        return (len(self.ground_truths) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        candidate, vacancies = self.ground_truths[idx]\n",
    "        req_ids, labels = vacancies.keys(), list(vacancies.values())\n",
    "\n",
    "        candidate_text = \"query: \" + self.cv_texts[candidate]\n",
    "        vacancy_texts = [\"passage: \" + self.req_texts[v] for v in req_ids]\n",
    "        input_texts = [candidate_text] + vacancy_texts\n",
    "        \n",
    "        # Tokenize together to ensure consistent padding\n",
    "        tokens = self.tokenizer(input_texts, add_special_tokens=True, padding=True, truncation=True, max_length=self.query_size, return_tensors='pt').to(device)\n",
    "\n",
    "        # Differentiating between -1 and 0 is practically impossible, so they are considered to be the same\n",
    "        labels = [i if i >=0 else 0 for i in labels]\n",
    "\n",
    "        return (candidate, list(req_ids)), tokens, torch.LongTensor(labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3009614-3db2-4606-8ff3-70c727d4ca6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(truth_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcefbc83-4ce6-4edf-a61b-14577754037a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = TokenDataLoader(dict(training_slice), cv_data, req_data, query_size=512, batch_size=1)\n",
    "val_dataloader = TokenDataLoader(dict(val_slice), cv_data, req_data, query_size=512, batch_size=1)\n",
    "test_dataloader = TokenDataLoader(dict(test_slice), cv_data, req_data, query_size=512, batch_size=1)\n",
    "\n",
    "if (create_train := not \"e5_trainloader.pth\" in os.listdir(\"./dataloaders/\")) or (create_test := not \"e5_testloader.pth\" in os.listdir(\"./dataloaders/\")):\n",
    "    torch.save(train_dataloader, './dataloaders/e5_trainloader.pth')\n",
    "    torch.save(test_dataloader, './dataloaders/e5_testloader.pth')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e6225-bf3c-4d08-895b-6384c9523fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def listwise_loss(scores, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the LambdaRank loss. (assume sigma=1.)\n",
    "    \n",
    "    scores: tensor of size [N, 1] (the output of a neural network), where N = length of <query, document> pairs\n",
    "    labels: tensor of size [N], contains the relevance labels \n",
    "    \n",
    "    returns: a tensor of size [N, 1]\n",
    "    \"\"\"\n",
    "    if labels.size(0) < 2:\n",
    "        return torch.Tensor([[0]])\n",
    "\n",
    "    N = torch.arange(len(scores))\n",
    "    num_docs = len(scores)\n",
    "\n",
    "    sigma = 1\n",
    "\n",
    "    # Calculate lambda_{i, j} for every <i, j>.\n",
    "    S_j = torch.stack([labels] * num_docs)\n",
    "    S_i = S_j.T\n",
    "\n",
    "    S = torch.nan_to_num((S_i - S_j) / (S_i - S_j).abs())\n",
    "    lamda = (sigma * (0.5 * (1 - S) - (1 / (1 + torch.exp(sigma * (scores - scores.T))))))\n",
    "\n",
    "    # Calculate abs(Delta-NDCG) for each ordering <i, j> combination\n",
    "    sorted_ind = torch.flip(scores.argsort(dim=0).flatten(), dims=[0])\n",
    "    sorted_labels = labels[sorted_ind]\n",
    "    ideal_labels = torch.sort(labels)[0].flip(dims=[0])\n",
    "    k = (torch.arange(sorted_labels.shape[0]) + 1).to(device)\n",
    "    DCG_ideal_labels = torch.sum((2**ideal_labels - 1) / torch.log(k + 1)) \n",
    "    doc_id_to_rank = torch.Tensor([(sorted_ind == i).nonzero(as_tuple=True)[0] for i in N]).int()\n",
    "    doc_id_to_label = torch.Tensor([sorted_labels[R_i] for R_i in doc_id_to_rank]).int().to(device)\n",
    "    \n",
    "    # Calculate delta NDCG\n",
    "    R_j = torch.stack([doc_id_to_rank] * num_docs).to(device)\n",
    "    R_i = R_j.T\n",
    "    label_j = torch.stack([doc_id_to_label] * num_docs).to(device)\n",
    "    label_i = label_j.T\n",
    "    DCG_discount = ((2**label_i - 1) / torch.log(R_i + 2) + (2**label_j - 1) / torch.log(R_j + 2)).to(device)\n",
    "    DCG_gain = ((2**label_j - 1) / torch.log(R_i + 2) + (2**label_i - 1) / torch.log(R_j + 2)).to(device)\n",
    "    delta_NDCG = ((DCG_gain - DCG_discount) / DCG_ideal_labels).abs()\n",
    "\n",
    "    lambda_rank_loss =  (lamda * delta_NDCG).sum(axis=1).unsqueeze(1) \n",
    "\n",
    "    return lambda_rank_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319102ca-4b2e-448a-b4f6-d15f34d70b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class e5_ranker(torch.nn.Module):\n",
    "    def __init__(self, pooling=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(\"intfloat/multilingual-e5-small\")\n",
    "        self.pooling = pooling\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "\n",
    "        # Process all embeddings in one go\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        if self.pooling == \"mean\":\n",
    "            # Mean pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size())\n",
    "            sum_embeddings = torch.sum(outputs.last_hidden_state * input_mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)  # Avoid division by zero\n",
    "            embeddings = sum_embeddings / sum_mask\n",
    "        elif self.pooling == \"sum\":\n",
    "            # Sum pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size())\n",
    "            embeddings = torch.sum(outputs.last_hidden_state * input_mask_expanded, 1)\n",
    "        elif self.pooling == \"max\":\n",
    "            # Max pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size()).bool()\n",
    "            masked_embeddings = outputs.last_hidden_state * input_mask_expanded  # Apply mask to zero out padding tokens\n",
    "            embeddings, _ = torch.max(masked_embeddings, dim=1)  # Obtain max across the sequence dimension\n",
    "        \n",
    "        # Extract CV and request embeddings\n",
    "        cv_embedding = embeddings[0].unsqueeze(0)  # CV is the first in the batch\n",
    "        req_embeddings = embeddings[1:]  # rest are requests\n",
    "            \n",
    "        # Use the cosine similarity as the score (based on the paper)\n",
    "        return F.cosine_similarity(cv_embedding, req_embeddings).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b612a-27d6-46c8-a2ab-5cce4c8f3b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, trainloader, use_wandb):\n",
    "    \"\"\"\n",
    "    Perform a single epoch of training.\n",
    "    \n",
    "    - Model: the model to train (should return ranking scores of CV-vacancy pairs)\n",
    "    - Optimizer: the optimizer to use\n",
    "    - Trainloader: the dataloader to use, which should provide tokens/embeddings/texts and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    ndcg_scores = []\n",
    "        \n",
    "    for i, (_, batch_data, batch_labels) in enumerate(trainloader):\n",
    "\n",
    "        # Make prediction\n",
    "        y_pred = model(batch_data.to(device))\n",
    "\n",
    "        # Calculate and propagate loss\n",
    "        optimizer.zero_grad()\n",
    "        ground_truth = batch_labels.squeeze()\n",
    "\n",
    "        if len(y_pred) > len(ground_truth):\n",
    "            y_pred = y_pred[:len(ground_truth)]\n",
    "        \n",
    "        lambda_i = listwise_loss(y_pred, ground_truth)\n",
    "        \n",
    "        torch.autograd.backward(y_pred, lambda_i.squeeze())\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if use_wandb:\n",
    "            # Log loss in wandb\n",
    "            wandb.log({\"loss\": lambda_i.squeeze().mean()})\n",
    "\n",
    "        score = ndcg_score(batch_labels.detach().cpu().unsqueeze(0), \n",
    "                           y_pred.unsqueeze(0).detach().cpu(), k=10)\n",
    "            \n",
    "        # Calculate nDCG score of current batch\n",
    "        ndcg_scores.append(score)\n",
    "        \n",
    "        \n",
    "        print(\"                                                                                                                    \", end=\"\\r\")\n",
    "        print(f\"Batch: {i + 1}/{len(trainloader)}, y_pred mean: {y_pred.mean()} ({y_pred.std()}), nDCG: {score}\", end=\"\\r\")\n",
    "        \n",
    "    return ndcg_scores\n",
    "\n",
    "\n",
    "def val_loop(model, valloader):\n",
    "    \"\"\"\n",
    "    Evaluate given model once.\n",
    "    \n",
    "    - Model: the model to train (should return ranking scores of CV-vacancy pairs)\n",
    "    - Valloader: the dataloader to use, which should provide tokens/embeddings/texts and labels\n",
    "    \"\"\"\n",
    "        \n",
    "    ndcg_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (_, batch_data, batch_labels) in enumerate(valloader):\n",
    "\n",
    "            print(f\"Batch: {i + 1}/{len(valloader)}\", end=\"\\r\")\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred_val = model(batch_data.to(device))\n",
    "\n",
    "            ground_truth = batch_labels.squeeze()\n",
    "\n",
    "            if len(y_pred_val) > len(ground_truth):\n",
    "                y_pred_val = y_pred_val[:len(ground_truth)]\n",
    "        \n",
    "            # Calculate nDCG score of current batch        \n",
    "            ndcg_scores.append(ndcg_score(batch_labels.detach().cpu().unsqueeze(0), \n",
    "                                y_pred_val.unsqueeze(0).detach().cpu(), k=10))\n",
    "            \n",
    "    return ndcg_scores\n",
    "\n",
    "\n",
    "def train_model(trial, trainloader, valloader, model_type=\"e5\", epochs=10, step_size=5, use_wandb=False):\n",
    "    \"\"\"\n",
    "    Trains a given model for a given amount of epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    best_score = 0\n",
    "    \n",
    "    # Search space\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-4, log=True)\n",
    "    pooling_method = trial.suggest_categorical('pooling_method', [\"mean\", \"max\", \"sum\"])\n",
    "    \n",
    "    if model_type == \"e5\":\n",
    "        # Train on GPU if available\n",
    "        model = e5_ranker(pooling=pooling_method).to(device)      \n",
    "        model.train()\n",
    "    elif model_type == \"consultantbert\":\n",
    "        # Train on GPU if available\n",
    "        model = conSultantBERT(pooling=pooling_method).to(device)      \n",
    "        model.train()\n",
    "    elif model_type == \"PJFNN\":\n",
    "        embedding_size = trial.suggest_categorical(\"embedding_size\", [64, 128, 256])\n",
    "        \n",
    "        model = PJFNN(embedding_size=embedding_size, geek_channels=1, job_channels=30, vocab=vocab)\n",
    "        model.train()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    if use_wandb:\n",
    "        # Set up WandB integration\n",
    "        wandb.init(project=\"recsys\", job_type=\"optimize\")\n",
    "\n",
    "        # Configuration for WandB\n",
    "        config = {\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"pooling\": pooling_method,\n",
    "            \"model\": model.__class__.__name__\n",
    "        }\n",
    "        wandb.config.update(config)\n",
    "\n",
    "    # We use Adam as the optimizer by default\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    \n",
    "    for epoch in range(epochs + 1):\n",
    "        print(f\"Epoch: {epoch}/{epochs}\")\n",
    "\n",
    "        # Train the model for the current epoch\n",
    "        epoch_ndcg_scores = train_loop(model, optimizer, trainloader, use_wandb)\n",
    "\n",
    "        print()\n",
    "        print(\"Training nDCG:\", np.mean(epoch_ndcg_scores))\n",
    "        print()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if use_wandb:\n",
    "            wandb.log({\"Training nDCG\": np.mean(epoch_ndcg_scores)})\n",
    "\n",
    "        ndcg_scores = []           \n",
    "\n",
    "        # Evaluate the model\n",
    "        val_ndcg_scores = val_loop(model, valloader)\n",
    "\n",
    "        print()\n",
    "        print(\"Testing nDCG:\", np.mean(val_ndcg_scores))\n",
    "        print()\n",
    "\n",
    "        if use_wandb:\n",
    "            wandb.log({\"Testing nDCG\": np.mean(val_ndcg_scores)})\n",
    "\n",
    "        if np.mean(val_ndcg_scores) > best_score:\n",
    "            torch.save(model.state_dict(), f\"./trained_models/{model.__class__.__name__}.pt\")\n",
    "            best_score = np.mean(val_ndcg_scores)\n",
    "            \n",
    "    return np.mean(val_ndcg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec75a2-c8d4-4acf-b24f-da59c51e51ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_wrapper(trainloader, valloader, model_type=\"e5\"):\n",
    "    def objective(trial):\n",
    "        return train_model(trial, trainloader, valloader, model_type=model_type, epochs=3, use_wandb=False)\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0470ad9-93c3-4ea8-8e41-06256c3ad067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "gc.collect()\n",
    "\n",
    "# Hide user/future warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# We need to provide trainloader and valloader to the training/validation loop\n",
    "wrapped_objective = objective_wrapper(train_dataloader, val_dataloader)\n",
    "\n",
    "# Start optimization\n",
    "study.optimize(wrapped_objective, n_trials=6)  \n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "\n",
    "with open(\"e5_results.txt\", \"w+\") as f:\n",
    "    json.dump(study.best_trial.params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf687f-ed36-416b-a242-f732e51fb615",
   "metadata": {},
   "source": [
    "# ConSultantBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd35743-00a4-4a3f-ad41-afc3b502d94f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb14b05-970e-4cc1-a734-ac37f6a50ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a96ba28-2819-4e49-bbf9-192ceb522e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTTokenDataLoader(Dataset):\n",
    "    def __init__(self, truth_dict, cv_data, req_data, query_size=512, batch_size=32):\n",
    "        self.ground_truths = list(truth_dict.items())\n",
    "        self.cv_texts = cv_data\n",
    "        self.req_texts = req_data\n",
    "        \n",
    "        self.query_size = query_size\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        # Adjust the length to account for the number of batches based on candidates\n",
    "        return (len(self.ground_truths) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        candidate, vacancies = self.ground_truths[idx]\n",
    "\n",
    "        req_ids, labels = vacancies.keys(), list(vacancies.values())\n",
    "\n",
    "        candidate_text = self.cv_texts[candidate]\n",
    "        vacancy_texts = [self.req_texts[v] for v in req_ids]\n",
    "        input_texts = [candidate_text] + vacancy_texts\n",
    "        \n",
    "        tokens = self.tokenizer(input_texts, max_length=self.query_size, padding='max_length', truncation=True, return_tensors=\"pt\").to(device)\n",
    "            \n",
    "        # Differentiating between -1 and 0 is practically impossible, so they are considered to be the same\n",
    "        labels = [i if i >=0 else 0 for i in labels]\n",
    "        \n",
    "        return (candidate, list(req_ids)), tokens, torch.LongTensor(labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cbc286-2d0a-4431-96f5-ebbdb714079e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = BERTTokenDataLoader(dict(training_slice), cv_data, req_data, query_size=512, batch_size=1)\n",
    "val_dataloader = BERTTokenDataLoader(dict(val_slice), cv_data, req_data, query_size=512, batch_size=1)\n",
    "test_dataloader = BERTTokenDataLoader(dict(test_slice), cv_data, req_data, query_size=512, batch_size=1)\n",
    "\n",
    "if (create_train := not \"bert_trainloader.pth\" in os.listdir(\"./dataloaders/\")) or (create_test := not \"bert_testloader.pth\" in os.listdir(\"./dataloaders/\")):\n",
    "    torch.save(train_dataloader, './dataloaders/bert_trainloader.pth')\n",
    "    torch.save(test_dataloader, './dataloaders/bert_testloader.pth')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddcc70c-1d4d-4345-a278-8f3d25385e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s3://s3-nl-prd-semrb-emr-datascience/volodymyr.medentsiy/models/sbert_v2_full_dataset_folder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d711bd-78c6-42c2-885f-3def29b1566f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class conSultantBERT(torch.nn.Module):\n",
    "    def __init__(self, pooling):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = BertModel.from_pretrained(\"bert-base-multilingual-cased\").to(device)    \n",
    "        self.pooling = pooling\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "\n",
    "        # Process all embeddings in one go\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        if self.pooling == \"mean\":\n",
    "            # Mean pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size())\n",
    "            sum_embeddings = torch.sum(outputs.last_hidden_state * input_mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)  # Avoid division by zero\n",
    "            embeddings = sum_embeddings / sum_mask\n",
    "        elif self.pooling == \"sum\":\n",
    "            # Sum pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size())\n",
    "            embeddings = torch.sum(outputs.last_hidden_state * input_mask_expanded, 1)\n",
    "        elif self.pooling == \"max\":\n",
    "            # Max pooling\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size()).bool()\n",
    "            masked_embeddings = outputs.last_hidden_state * input_mask_expanded  # Apply mask to zero out padding tokens\n",
    "            embeddings, _ = torch.max(masked_embeddings, dim=1)  # Obtain max across the sequence dimension\n",
    "        \n",
    "        # Extract CV and request embeddings\n",
    "        cv_embedding = embeddings[0].unsqueeze(0)  # CV is the first in the batch\n",
    "        req_embeddings = embeddings[1:]  # rest are requests\n",
    "            \n",
    "        # Use the cosine similarity as the score (based on the paper)\n",
    "        return F.cosine_similarity(cv_embedding, req_embeddings).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e7d20-6277-4d04-aec0-9de805c140ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "gc.collect()\n",
    "\n",
    "# Hide user/future warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# We need to provide trainloader and valloader to the training/validation loop\n",
    "wrapped_objective = objective_wrapper(train_dataloader, val_dataloader, model_type=\"consultantbert\")\n",
    "\n",
    "# Start optimization\n",
    "study.optimize(wrapped_objective, n_trials=12)  \n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "\n",
    "with open(\"consultantbert_results.txt\", \"w+\") as f:\n",
    "    json.dump(study.best_trial.params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf0e97-7271-4fda-aad6-6edced638794",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d67f30-75c1-46d4-8b78-a09ae5cac69e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106f097-a4ab-4293-bdc7-187b2e8b3d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time \n",
    "from torch_geometric.data import Data, HeteroData, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.nn import to_hetero\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f069fb2-4666-429d-ab8b-7fa240e06d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloader = torch.load(\"./dataloaders/graph_trainloader.pth\")\n",
    "valloader = torch.load(\"./dataloaders/graph_valloader.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd214a6f-e1fa-4d87-ab57-0d0d2ddf16f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97e77f-6437-4fd5-9618-3932f1f9e913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We embed the textual nodes (candidates and requests) separately at first\n",
    "class text_embedding_layer(torch.nn.Module):\n",
    "    def __init__(self, text_embedding_size=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.e5 = AutoModel.from_pretrained(\"intfloat/multilingual-e5-small\").to(device)\n",
    "                \n",
    "        self.candidate_out = nn.Linear(in_features=384,\n",
    "                                       out_features=text_embedding_size)\n",
    "\n",
    "        self.company_out = nn.Linear(in_features=384,\n",
    "                                     out_features=text_embedding_size)\n",
    "        \n",
    "    def average_pool(self, last_hidden_states, attention_mask):\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "        \n",
    "    def forward(self, x_can, x_req, att_mask_can, att_mask_req):\n",
    "        \n",
    "        # Feed tokens into model\n",
    "        x_candidate = self.e5(x_can, att_mask_can)\n",
    "        x_company = self.e5(x_req, att_mask_req)\n",
    "        \n",
    "        # Create embedding tensor\n",
    "        candidate_embeddings = self.average_pool(x_candidate.last_hidden_state, attention_mask=att_mask_can)\n",
    "        company_embeddings = self.average_pool(x_company.last_hidden_state, attention_mask=att_mask_req)\n",
    "\n",
    "        # normalize embeddings\n",
    "        candidate_embeddings = F.normalize(candidate_embeddings, p=2, dim=1)\n",
    "        company_embeddings = F.normalize(company_embeddings, p=2, dim=1)\n",
    "        \n",
    "        # Run through MLP to match other embedding sizes\n",
    "        x_candidate = self.candidate_out(candidate_embeddings).float()\n",
    "        x_company = self.company_out(company_embeddings).float()\n",
    "        \n",
    "        return x_candidate, x_company    \n",
    "    \n",
    "# Then, we embed all nodes initially\n",
    "class embedding_layer(torch.nn.Module):\n",
    "    def __init__(self, embedding_size=32):\n",
    "        super().__init__()        \n",
    "        \n",
    "        # self.conv = geom_nn.GATv2Conv((-1, -1), out_channels)        \n",
    "        # self.conv = geom_nn.SimpleConv((-1, -1)) #, embedding_size)\n",
    "        self.conv = geom_nn.TransformerConv((-1, -1), embedding_size)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "        return self.conv(x, edge_index)\n",
    "        \n",
    "    \n",
    "class baselineGNNModel(torch.nn.Module):\n",
    "    def __init__(self, data, typings, text_embedding_size=16, embedding_size=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.typings = typings\n",
    "        \n",
    "        self.text_embedder = text_embedding_layer(text_embedding_size=text_embedding_size)\n",
    "\n",
    "        self.embedder = embedding_layer(embedding_size=embedding_size)\n",
    "        self.embedder = to_hetero(self.embedder, data.metadata(), aggr='sum')        \n",
    "        \n",
    "        self.fc = nn.Linear(embedding_size, 1)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # Embed textual features       \n",
    "        x_candidate, x_request = self.text_embedder(data.x_dict[\"candidate\"], data.x_dict[\"vacancy\"], data[\"candidate\"].att_mask, data[\"vacancy\"].att_mask)\n",
    "        \n",
    "        # Store the textual embeddings along with the rest of the graph\n",
    "        data.x_dict[\"candidate\"] = x_candidate\n",
    "        data.x_dict[\"vacancy\"] = x_request\n",
    "\n",
    "        # Embed the graph as a whole\n",
    "        embedded_data = self.embedder({k: v.float() for k, v in data.x_dict.items()}, data.edge_index_dict)\n",
    "        \n",
    "        # Each sub-graph gets its own embedding\n",
    "        sub_graphs = defaultdict(list)\n",
    "            \n",
    "        # Find the sub-graph of each node in the embedding, and add it to the corresponding list\n",
    "        for typing in self.typings:\n",
    "            for i, emb in enumerate(embedded_data[typing]):            \n",
    "                # Some subgraphs do not have all data types (e.g., a graph might not include any education nodes)\n",
    "                if data[typing]:\n",
    "                    # Find the sub-graph the current node belongs to\n",
    "                    current_node_id = int(data[typing].unique_node_id[i].item())\n",
    "                                        \n",
    "                    # We were working with a dummy node\n",
    "                    if current_node_id == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    sg = int(data[typing].sub_graph[i].item())\n",
    "                                        \n",
    "                    # Add its candidate embedding to its sub-graph embedding\n",
    "                    sub_graphs[sg].append(emb.unsqueeze(0))              \n",
    "\n",
    "        # Finally, mean pool every graph embedding (so the final embedding is the mean of all of the nodes)\n",
    "        for sg in sub_graphs.keys():            \n",
    "            sub_graphs[sg] = torch.mean(torch.stack(sub_graphs[sg]).squeeze(1), dim=0)\n",
    "                                    \n",
    "        # Stack all the sub-graph embeddings into a single matrix, both candidate- and company-sided\n",
    "        sub_graphs = torch.stack([i[1] for i in sorted(sub_graphs.items())], dim=0)\n",
    "                \n",
    "        # Make predictions based on the sub-graph embeddings\n",
    "        y_pred = self.fc(sub_graphs)\n",
    "        \n",
    "        return y_pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1bb0c-f3f5-46bd-a54d-cfba260ed312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, trainloader, valloader, epochs=10):\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(trainloader):  \n",
    "\n",
    "            # Make prediction\n",
    "            y_pred = model(data.detach().clone().to(device))\n",
    "\n",
    "            print(\"                                                                                                                    \", end=\"\\r\")\n",
    "            print(f\"Epoch: {epoch + 1}/{epochs}, batch (train): {i + 1}/{len(trainloader)}, y_pred mean: {y_pred.mean()}\", end=\"\\r\")\n",
    "\n",
    "            # Calculate and backpropagate gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if len(y_pred) > len(data.y):\n",
    "                y_pred = y_pred[:len(data.y)]\n",
    "            \n",
    "            lambda_i = listwise_loss(y_pred, data.y.to(device))\n",
    "            torch.autograd.backward(y_pred, lambda_i.squeeze())\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate nDCG score of current batch\n",
    "            ndcg_scores.append(ndcg_score(data.y.unsqueeze(0).cpu(), \n",
    "                                          y_pred.unsqueeze(0).detach().cpu(), k=10))\n",
    "            \n",
    "        # Log epoch-level metrics to WandB\n",
    "        print(f\"\\n\\nTraining nDCG: {np.mean(ndcg_scores)}\\n\")\n",
    "        ndcg_scores = []\n",
    "        \n",
    "        # Evaluate model\n",
    "        ndcg_val = val_loop(model, valloader)\n",
    "        print(f\"\\nValidation nDCG: {np.mean(ndcg_val)}\\n\")\n",
    "        \n",
    "    # Return nDCG of final trained model\n",
    "    return ndcg_val\n",
    "\n",
    "def val_loop(model, valloader):\n",
    "    ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data_val in enumerate(valloader):\n",
    "            print(f\"Batch (val): {i + 1}/{len(valloader)}\", end=\"\\r\")\n",
    "            \n",
    "            # Make prediction\n",
    "            y_pred_val = model(data_val.detach().clone().to(device))\n",
    "\n",
    "            if len(y_pred_val) > len(data_val.y):\n",
    "                y_pred_val = y_pred[:len(data_val.y)]\n",
    "             \n",
    "            # Calculate nDCG score of current batch   \n",
    "            ndcg_scores.append(ndcg_score(data_val.y.unsqueeze(0).cpu(), \n",
    "                                           y_pred_val.unsqueeze(0).detach().cpu(), k=10))\n",
    "            \n",
    "    return ndcg_scores\n",
    "\n",
    "\n",
    "def optimize_model(trial, trainloader, valloader, epochs=10):\n",
    "    \n",
    "    \n",
    "    # Data.metadata() is needed to initialize the heterodata\n",
    "    data = next(iter(trainloader))\n",
    "\n",
    "    # Search space\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-3, log=True)\n",
    "    text_embedding_size = trial.suggest_categorical('text_embedding_size', [32, 128, 256])\n",
    "    embedding_size = trial.suggest_categorical('embedding_size', [32, 128, 256])           \n",
    "\n",
    "        \n",
    "    # All the different node types\n",
    "    typings = [\"candidate\", \"vacancy\", \"city\", \"education\", \"job_type\", \"industry\", \"klass\", \"literal\"]\n",
    "\n",
    "    \n",
    "    # Initiate the model (number of heads is locked, as that is required for the multi-explanation component to function)\n",
    "    model = baselineGNNModel(data,\n",
    "                             typings,\n",
    "                             text_embedding_size=text_embedding_size,\n",
    "                             embedding_size=embedding_size).to(device)\n",
    "                                        \n",
    "    # Configuration for WandB\n",
    "    config = {\n",
    "        \"model\": model.__class__.__name__,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"text_embedding_size\": text_embedding_size,\n",
    "        \"embedding_size\": embedding_size\n",
    "    }    \n",
    "\n",
    "    print(f\"\"\"\\nConfig:\\n- learning_rate = {learning_rate}\\n- text_embedding_size = {text_embedding_size}\\n- embedding_size = {embedding_size}\\n\\n\"\"\")\n",
    "\n",
    "    # Configure Adam\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    start_time = time.time() \n",
    "    # Train and evaluate model\n",
    "    ndcg_scores_val = train_loop(model, optimizer, trainloader, valloader, epochs=epochs)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Training for {epochs} epochs took {end_time - start_time} seconds ({(end_time - start_time) / epochs} seconds per epoch)\")\n",
    "    \n",
    "    return np.mean(ndcg_scores_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab11fff-8e00-4813-9a24-d53f6c4c310f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_wrapper(trainloader, valloader):\n",
    "    def objective(trial):\n",
    "        return optimize_model(trial, trainloader, valloader, epochs=6)\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40cf566-2356-45d3-bccd-7f7deb2fbef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "gc.collect()\n",
    "\n",
    "# Hide user/future warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# We need to provide trainloader and valloader to the training/validation loop\n",
    "wrapped_objective = objective_wrapper(trainloader, valloader)\n",
    "\n",
    "# Start optimization\n",
    "study.optimize(wrapped_objective, n_trials=6)  \n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "\n",
    "with open(\"base_gnn_results.txt\", \"w+\") as f:\n",
    "    json.dump(study.best_trial.params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce87bd4-ab03-4bc9-b0ed-9a9de6da31ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
